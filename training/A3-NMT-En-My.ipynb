{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation + Transformer\n",
    "\n",
    "<img src = \"../figures/transformer1.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyidaungsu in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (0.1.4)\n",
      "Requirement already satisfied: numpy in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from pyidaungsu) (1.26.3)\n",
      "Requirement already satisfied: python-crfsuite in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from pyidaungsu) (0.9.10)\n",
      "Requirement already satisfied: emoji in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from pyidaungsu) (2.10.1)\n",
      "Requirement already satisfied: pybind11 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from pyidaungsu) (2.11.1)\n",
      "Requirement already satisfied: fasttext in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from pyidaungsu) (0.9.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from fasttext->pyidaungsu) (68.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyidaungsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch, torchdata, torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyidaungsu as pds\n",
    "\n",
    "import random, math, time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.16.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. ETL: Loading the dataset\n",
    "\n",
    "**Note**: Here I chose to translate English to German, simply it is easier for myself, since I don't understand German so it is difficult for me to imagine a sentence during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext, datasets\n",
    "\n",
    "SRC_LANGUAGE = 'en'\n",
    "TRG_LANGUAGE = 'my'\n",
    "\n",
    "# train = Multi30k(split=('train'), language_pair=(SRC_LANGUAGE, TRG_LANGUAGE))\n",
    "dataset = datasets.load_dataset('myothiha/mm_eng_alt_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [(row['en'], row['my']) for row in dataset['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
       " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. EDA - simple investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
       " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's take a look at one example of train\n",
    "sample = train[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16280"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(train)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 29001 is plenty,, we gonna call `random_split` to train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, test = train.random_split(total_length=train_size, weights = {\"train\": 0.7, \"val\": 0.2, \"test\": 0.1}, seed=999)\n",
    "val = [(row['en'], row['my']) for row in dataset['validation']]\n",
    "test = [(row['en'], row['my']) for row in dataset['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16280"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(train)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1809"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = len(val)\n",
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = len(test)\n",
    "test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Preprocessing \n",
    "\n",
    "### Tokenizing\n",
    "\n",
    "**Note**: the models must first be downloaded using the following on the command line: \n",
    "```\n",
    "python3 -m spacy download en_core_web_sm\n",
    "python3 -m spacy download de_core_news_sm\n",
    "```\n",
    "\n",
    "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_sm\n",
    "# !python3 -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Myanmar word tokenizer.\n",
    "def mmtokenizer(sentence):\n",
    "    return pds.tokenize(sentence, form=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform[TRG_LANGUAGE] = mmtokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
       " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  \" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။\n",
      "Tokenization:  ['\"', 'ဒီ', 'ဟာ', 'သည်', 'အဲ့ဒီ', 'အချိန်', 'တုန်း', 'က', 'လက်ရာ', 'အမြောက်ဆုံး', 'ဖြစ်', 'တာ', 'ကြောင့်', 'တာ', 'ပို', 'ဆာရစ်မက်နဘုရား', 'ကျောင်း', 'ဖြစ်', 'လိမ့်', 'မယ်', 'လို့', '\"', 'သူ', 'မ', 'ခံစား', 'ရ', 'ပါ', 'သည်', '။']\n"
     ]
    }
   ],
   "source": [
    "#example of tokenization of the english part\n",
    "print(\"Sentence: \", sample[1])\n",
    "print(\"Tokenization: \", token_transform[TRG_LANGUAGE](sample[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to tokenize our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to yield list of tokens\n",
    "# here data can be `train` or `val` or `test`\n",
    "def yield_tokens(data, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data:\n",
    "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for token in yield_tokens(train, TRG_LANGUAGE):\n",
    "    tokens.append(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Text to integers (Numericalization)\n",
    "\n",
    "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
       " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object \n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln), \n",
    "                                                    min_freq=2,   #The minimum frequency needed to include a token in the vocabulary. if not, everything will be treated as UNK\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end                                            \n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[795, 18, 12, 0, 12]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see some example\n",
    "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vessel'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can reverse it....\n",
    "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
    "\n",
    "#print 1816, for example\n",
    "mapping[1891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try unknown vocab\n",
    "mapping[0]\n",
    "#they will all map to <unk> which has 0 as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<pad>', '<sos>', '<eos>')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try special symbols\n",
    "mapping[1], mapping[2], mapping[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16009"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique vocabularies\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Preparing the dataloader\n",
    "\n",
    "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([SOS_IDX]), \n",
    "                      torch.tensor(token_ids), \n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and trg language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], # Tokenization\n",
    "                                               vocab_transform[ln], # Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tesors\n",
    "def collate_batch(batch):\n",
    "    src_batch, src_len_batch, trg_batch = [], [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
    "        src_batch.append(processed_text)\n",
    "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
    "        src_len_batch.append(processed_text.size(0))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
    "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, val, and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(val,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for en, len, de in train_loader:\n",
    "#     break\n",
    "\n",
    "# print(en[1])\n",
    "# print(len[1])\n",
    "# print(de[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the train loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for en, _, de in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English shape:  torch.Size([64, 58])\n",
      "German shape:  torch.Size([64, 77])\n"
     ]
    }
   ],
   "source": [
    "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
    "print(\"German shape: \", de.shape)   # (batch_size, seq len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Design the model\n",
    "\n",
    "<img src=\"../figures/transformer-encoder.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout              = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        #src = [batch size, src len, hid dim]\n",
    "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        #src: [batch_size, src len, hid dim]\n",
    "        \n",
    "        _src    = self.feedforward(src)\n",
    "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
    "        #src: [batch_size, src len, hid dim]\n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 500):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
    "                                           for _ in range(n_layers)])\n",
    "        self.dropout       = nn.Dropout(dropout)\n",
    "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
    "        \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        src_len    = src.shape[1]\n",
    "        \n",
    "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        #pos: [batch_size, src_len]\n",
    "        \n",
    "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        #src: [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        #src: [batch_size, src_len, hid_dim]\n",
    "        \n",
    "        return src\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutli Head Attention Layer\n",
    "\n",
    "<img src = \"../figures/transformer-attention.png\" width=\"700\">\n",
    "\n",
    "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "# forward(src, src, src, src_mask)\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        assert hid_dim % n_heads == 0\n",
    "        self.hid_dim  = hid_dim\n",
    "        self.n_heads  = n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        \n",
    "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
    "        #Additional linear layer for additive attention mechanism\n",
    "        self.w1 = nn.Linear(self.head_dim, self.head_dim)\n",
    "        self.w2 = nn.Linear(self.head_dim, self.head_dim)\n",
    "        self.vt = nn.Linear(self.head_dim, 1)\n",
    "\n",
    "        \n",
    "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "                \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        #src, src, src, src_mask\n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        #Q=K=V: [batch_size, src len, hid_dim]\n",
    "        \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        #Q = [batch_size, n heads, query len, head_dim]\n",
    "        \n",
    "        # General\n",
    "        # energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "\n",
    "        # Scaled Multiplicative Attention\n",
    "        # K_ = self.fc_w(K)\n",
    "        # # Q @ W @ KT (W is weight with d2 x d1 dimension [head_dim, head_dim])\n",
    "        # energy = torch.matmul(Q, K_.transpose(-2, -1)) / self.scale\n",
    "\n",
    "        # Additive Attention\n",
    "        q_len = query.shape[1]\n",
    "        qw1 = self.w1(Q).view(batch_size, self.n_heads, q_len, 1, self.head_dim)\n",
    "\n",
    "        k_len = key.shape[1]\n",
    "        kw2 = self.w2(K).view(batch_size, self.n_heads, 1, k_len, self.head_dim)\n",
    "\n",
    "        energy = torch.tanh(qw1 + kw2)\n",
    "        # energy = self.vt(energy).view(batch_size, self.n_heads, q_len, k_len @ self.n_heads, 1)\n",
    "        energy = self.vt(energy).squeeze(-1)\n",
    "\n",
    "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
    "        #energy = [batch_size, n heads, query len, key len]\n",
    "        \n",
    "        #for making attention to padding to 0\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "            \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "        #attention = [batch_size, n heads, query len, key len]\n",
    "        \n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
    "        #x = [batch_size, n heads, query len, head dim]\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
    "        #x = [batch_size, query len, n heads, head dim]\n",
    "        \n",
    "        x = x.view(batch_size, -1, self.hid_dim)\n",
    "        #x = [batch_size, query len, hid dim]\n",
    "        \n",
    "        x = self.fc_o(x)\n",
    "        #x = [batch_size, query len, hid dim]\n",
    "        \n",
    "        return x, attention\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position-wise Feedforward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = [batch size, src len, hid dim]\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decoder Layer\n",
    "\n",
    "<img src = \"../figures/transformer-decoder.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
    "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
    "        self.dropout              = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
    "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        \n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        #attention = [batch_size, n heads, trg len, src len]\n",
    "        \n",
    "        _trg = self.feedforward(trg)\n",
    "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "        #trg = [batch_size, trg len, hid dim]\n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, \n",
    "                 pf_dim, dropout, device,max_length = 500):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
    "                                            for _ in range(n_layers)])\n",
    "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout       = nn.Dropout(dropout)\n",
    "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len    = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        #pos: [batch_size, trg len]\n",
    "        \n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "        #trg: [batch_size, trg len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
    "            \n",
    "        #trg: [batch_size, trg len, hid dim]\n",
    "        #attention: [batch_size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        #output = [batch_size, trg len, output_dim]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together (become Seq2Seq!)\n",
    "\n",
    "Our `trg_sub_mask` will look something like this (for a target with 5 tokens):\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 0\\\\\n",
    "1 & 1 & 1 & 1 & 1\\\\\n",
    "\\end{matrix}$$\n",
    "\n",
    "The \"subsequent\" mask is then logically anded with the padding mask, this combines the two masks ensuring both the subsequent tokens and the padding tokens cannot be attended to. For example if the last two tokens were `<pad>` tokens the mask would look like:\n",
    "\n",
    "$$\\begin{matrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "1 & 1 & 1 & 0 & 0\\\\\n",
    "\\end{matrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        \n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        return src_mask\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        \n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        #trg_sub_mask = [trg len, trg len]\n",
    "            \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len]\n",
    "\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "\n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIM = len(vocab_transform[SRC_LANGUAGE])\n",
    "# OUTPUT_DIM = len(vocab_transform[TRG_LANGUAGE])\n",
    "# HID_DIM = 256\n",
    "# ENC_LAYERS = 3\n",
    "# DEC_LAYERS = 3\n",
    "# ENC_HEADS = 8\n",
    "# DEC_HEADS = 8\n",
    "# ENC_PF_DIM = 512\n",
    "# DEC_PF_DIM = 512\n",
    "# ENC_DROPOUT = 0.1\n",
    "# DEC_DROPOUT = 0.1\n",
    "\n",
    "# enc = Encoder(INPUT_DIM, \n",
    "#               HID_DIM, \n",
    "#               ENC_LAYERS, \n",
    "#               ENC_HEADS, \n",
    "#               ENC_PF_DIM, \n",
    "#               ENC_DROPOUT, \n",
    "#               device)\n",
    "\n",
    "# dec = Decoder(OUTPUT_DIM, \n",
    "#               HID_DIM, \n",
    "#               DEC_LAYERS, \n",
    "#               DEC_HEADS, \n",
    "#               DEC_PF_DIM, \n",
    "#               DEC_DROPOUT, \n",
    "#               device)\n",
    "\n",
    "# SRC_PAD_IDX = PAD_IDX\n",
    "# TRG_PAD_IDX = PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(16009, 256)\n",
       "    (pos_embedding): Embedding(500, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w1): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (w2): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(12318, 256)\n",
       "    (pos_embedding): Embedding(500, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w1): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (w2): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (w1): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (w2): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=12318, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
    "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
    "hid_dim = 256\n",
    "enc_layers = 3\n",
    "dec_layers = 3\n",
    "enc_heads = 8\n",
    "dec_heads = 8\n",
    "enc_pf_dim = 512\n",
    "dec_pf_dim = 512\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1\n",
    "\n",
    "SRC_PAD_IDX = PAD_IDX\n",
    "TRG_PAD_IDX = PAD_IDX\n",
    "\n",
    "enc = Encoder(input_dim, \n",
    "            hid_dim, \n",
    "            enc_layers, \n",
    "            enc_heads, \n",
    "            enc_pf_dim, \n",
    "            enc_dropout, \n",
    "            device)\n",
    "\n",
    "dec = Decoder(output_dim, \n",
    "            hid_dim, \n",
    "            dec_layers, \n",
    "            dec_heads, \n",
    "            dec_pf_dim, \n",
    "            enc_dropout, \n",
    "            device)\n",
    "\n",
    "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4098304\n",
      "128000\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "3153408\n",
      "128000\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      " 65536\n",
      "   256\n",
      "  1024\n",
      "    32\n",
      "  1024\n",
      "    32\n",
      "    32\n",
      "     1\n",
      " 65536\n",
      "   256\n",
      "131072\n",
      "   512\n",
      "131072\n",
      "   256\n",
      "3153408\n",
      " 12318\n",
      "______\n",
      "14646407\n"
     ]
    }
   ],
   "source": [
    "#we can print the complexity by the number of parameters\n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.0005\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll define our training loop. This is the exact same as the one used in the previous tutorial.\n",
    "\n",
    "As we want our model to predict the `<eos>` token but not have it be an input into our model we simply slice the `<eos>` token off the end of the sequence. Thus:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\n",
    "\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\n",
    "\\end{align*}$$\n",
    "\n",
    "$x_i$ denotes actual target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the `<eos>` token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "$y_i$ denotes predicted target sequence element. We then calculate our loss using the original `trg` tensor with the `<sos>` token sliced off the front, leaving the `<eos>` token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\\\\\n",
    "\\text{trg[1:]} &= [x_1, x_2, x_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "We then calculate our losses and update our parameters as is standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for src, src_len, trg in loader:\n",
    "        \n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg    = [batch size, trg len]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.reshape(-1, output_dim)\n",
    "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg    = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, loader_length):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for src, src_len, trg in loader:\n",
    "        \n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / loader_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together\n",
    "\n",
    "Finally, we train our actual model. This model is almost 3x faster than the convolutional sequence-to-sequence model and also achieves a lower validation perplexity!\n",
    "\n",
    "**Note: similar to CNN, this model always has a teacher forcing ratio of 1, i.e. it will always use the ground truth next token from the target sequence (this is simply because CNN do everything in parallel so we cannot have the next token). This means we cannot compare perplexity values against the previous models when they are using a teacher forcing ratio that is not 1. To understand this, try run previous tutorials with teaching forcing ratio of 1, you will get very low perplexity.  **   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_length = len(list(iter(train_loader)))\n",
    "val_loader_length   = len(list(iter(valid_loader)))\n",
    "test_loader_length  = len(list(iter(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 40m 47s\n",
      "\tTrain Loss: 5.415 | Train PPL: 224.856\n",
      "\t Val. Loss: 4.464 |  Val. PPL:  86.869\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "num_epochs = 1\n",
    "clip       = 1\n",
    "\n",
    "save_path = f'models/{model.__class__.__name__}.pt'\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
    "    \n",
    "    #for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    \n",
    "    #lower perplexity is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(train_losses, label = 'train loss')\n",
    "ax.plot(valid_losses, label = 'valid loss')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.449 | Test PPL:  85.562 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test on some random news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,   323,  7304,    13,    11,    32,    93,    29,     0,     0,\n",
       "          125,    32,    16,     4,   145, 11286,  2562,     7,    60,    64,\n",
       "            6,    11,     3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
    "src_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,   34,   77,   93,    4, 1013,  123, 1454,   11, 2755,    0,   19,\n",
       "          84,   95,   84,  152,    0,  210,   19,   52,  212,   73,   34,   15,\n",
       "          26,  338,   30,   23,    4,    8,    3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
    "trg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_text = trg_text.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 23]), torch.Size([1, 31]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_text.shape, trg_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, attentions = model(src_text, trg_text) #turn off teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 31, 12318])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape #batch_size, trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since batch size is 1, we just take off that dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 12318])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall remove the first token since it's zeroes anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 12318])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output[1:]\n",
    "output.shape #trg_len, trg_output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we just take the top token with highest probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_max = output.argmax(1) #returns max indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 72,  54,   0,   0,  11,  31,  11,  15,   9,  11,  23,   6,  19,   6,\n",
       "         22,  11,   6,  23,  43,  44,  41,  28,  11, 142,  30,   4,  39,   8,\n",
       "          3,  11])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the mapping of the target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ကျွန်တော်\n",
      "နေ့\n",
      "<unk>\n",
      "<unk>\n",
      "က\n",
      "မှာ\n",
      "က\n",
      "သူ\n",
      "များ\n",
      "က\n",
      "ပါ\n",
      "ကို\n",
      "ဖြစ်\n",
      "ကို\n",
      "ပြီး\n",
      "က\n",
      "ကို\n",
      "ပါ\n",
      "မည်\n",
      "”\n",
      "ပြော\n",
      "ဟု\n",
      "က\n",
      "ဟုတ်\n",
      "ရ\n",
      "သည်\n",
      "တယ်\n",
      "။\n",
      "<eos>\n",
      "က\n"
     ]
    }
   ],
   "source": [
    "for token in output_max:\n",
    "    print(mapping[token.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Attention\n",
    "\n",
    "Let's display the attentions to understand how the source text links with the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 31, 23])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 23])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = attentions[0, 0, :, :]\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'She',\n",
       " 'feels',\n",
       " 'that',\n",
       " '\"',\n",
       " 'it',\n",
       " 'could',\n",
       " 'be',\n",
       " 'Taposiris',\n",
       " 'Magna',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'most',\n",
       " 'sacred',\n",
       " 'temple',\n",
       " 'of',\n",
       " 'its',\n",
       " 'time',\n",
       " '.',\n",
       " '\"',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'ကျွန်တော်',\n",
       " 'နေ့',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " 'က',\n",
       " 'မှာ',\n",
       " 'က',\n",
       " 'သူ',\n",
       " 'များ',\n",
       " 'က',\n",
       " 'ပါ',\n",
       " 'ကို',\n",
       " 'ဖြစ်',\n",
       " 'ကို',\n",
       " 'ပြီး',\n",
       " 'က',\n",
       " 'ကို',\n",
       " 'ပါ',\n",
       " 'မည်',\n",
       " '”',\n",
       " 'ပြော',\n",
       " 'ဟု',\n",
       " 'က',\n",
       " 'ဟုတ်',\n",
       " 'ရ',\n",
       " 'သည်',\n",
       " 'တယ်',\n",
       " '။',\n",
       " '<eos>',\n",
       " 'က']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
    "trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=10)\n",
    "    \n",
    "    y_ticks =  [''] + translation\n",
    "    x_ticks =  [''] + sentence \n",
    "     \n",
    "    ax.set_xticklabels(x_ticks, rotation=45)\n",
    "    ax.set_yticklabels(y_ticks)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/43_5rtyn5lz1p4vkq89ykdw40000gn/T/ipykernel_48721/59549304.py:17: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(x_ticks, rotation=45)\n",
      "/var/folders/dq/43_5rtyn5lz1p4vkq89ykdw40000gn/T/ipykernel_48721/59549304.py:18: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels(y_ticks)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4096 (\\N{MYANMAR LETTER KA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4155 (\\N{MYANMAR CONSONANT SIGN MEDIAL YA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4157 (\\N{MYANMAR CONSONANT SIGN MEDIAL WA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4116 (\\N{MYANMAR LETTER NA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4154 (\\N{MYANMAR SIGN ASAT}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4112 (\\N{MYANMAR LETTER TA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4145 (\\N{MYANMAR VOWEL SIGN E}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4140 (\\N{MYANMAR VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4151 (\\N{MYANMAR SIGN DOT BELOW}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4121 (\\N{MYANMAR LETTER MA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4158 (\\N{MYANMAR CONSONANT SIGN MEDIAL HA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4126 (\\N{MYANMAR LETTER SA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4144 (\\N{MYANMAR VOWEL SIGN UU}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4152 (\\N{MYANMAR SIGN VISARGA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4117 (\\N{MYANMAR LETTER PA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4139 (\\N{MYANMAR VOWEL SIGN TALL AA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4141 (\\N{MYANMAR VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4143 (\\N{MYANMAR VOWEL SIGN U}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4118 (\\N{MYANMAR LETTER PHA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4156 (\\N{MYANMAR CONSONANT SIGN MEDIAL RA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4101 (\\N{MYANMAR LETTER CA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4142 (\\N{MYANMAR VOWEL SIGN II}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4106 (\\N{MYANMAR LETTER NNYA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4127 (\\N{MYANMAR LETTER HA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4123 (\\N{MYANMAR LETTER RA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4122 (\\N{MYANMAR LETTER YA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4171 (\\N{MYANMAR SIGN SECTION}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq0AAANYCAYAAADudNS1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACTQUlEQVR4nOzdeVxU5fv/8WsQHdwYd0VB3Mo9l3BB/QiVSlp+NE3DrLRNsmjXAm2hlfYs/dhqkVq2mVq4lKlhu6JRSu6KYi65sSkMy1y/P/xxvkygKXKYA7yej8c8yjkz93XPcGbmPffc5z42VVUBAAAALMzL0x0AAAAA/g2hFQAAAJZHaAUAAIDlEVoBAABgeYRWAAAAWB6hFQAAAJZHaAUAAIDlEVoBAABgeYRWAAAAWB6hFQAAAJZHaAVQpXEmawCoGAitAKosl8slNptNRETy8/NFhBALAFZFaAVQJblcLvHyOv0W+Morr8j9998vOTk5RogFAFgLoRVAlVI4kloYWB966CF59dVX5aKLLpKDBw8Wux0AwBq8Pd0BACgvWVlZUqdOHePfH330kcydO1e++uor6dWrl4icniZw8uRJcTgcnuomAKAEjLQCqBJuueUWWbBggYj83yjq1q1bZeDAgdKrVy/ZvHmzvP7669K9e3fp3LmzvPnmm57s7jkpfBz79++XAwcOyM6dOz3cIwAwD6EVQJXQqVMnmThxooiIOJ1OEREJDAyUzz//XO6991657rrr5IcffpBbb71Vrr/+ennwwQfl0KFDHuzx2amq2Gw2WbJkiVx99dUSFhYmAwYMkGnTpsmBAwc83T0AKHNMDwBQqRUecDVlyhQREXn77bdlz549EhUVJePHj5fjx4/LokWLJDIyUgYNGiQXXXSRbN26VX744Qcj3FqRzWaTlStXyvXXXy8vv/yyjBw5Ur788ku54447ZMCAAdK8eXNPdxEAypRNOdoAQCVWdJUAEZGpU6fK119/LePGjZPIyEipW7euZGdnS82aNUVVJS8vT0aOHCkFBQWyYsUKS68mcN9994nNZpNXX31Vdu/eLVdeeaWEhobK22+/7emuAUCZY6QVQKWlqkZgnTBhguTl5clHH30kqiqff/655Ofny9133y316tWTrKws+fLLL+Wdd96RtLQ0WbdundhstmKh1yry8/Nlw4YNMm7cOMnJyZGBAwfKVVddZczFff3116VHjx7yn//8x8M9RVmw6n4IlCdeAQAqHZfLZcz5FDl9wNX27duNOa0vvfSShISEyJIlS2TWrFmSnp4uTqdTjhw5Ip07d5b169dL9erVJT8/3zJBofBHsczMTCkoKBBvb28ZPny4LFq0SFq1aiUjRoyQ2bNni81mk/z8fPn1119l6dKlxkkTUDF9/vnnInJ6iTaXy2VKjTO1a1Y9oLSYHgCgUin8qb/Qe++9J1988YXUr19f4uLipKCgQGrUqCEiIg888IB8//33MmrUKImMjJTatWsbIbWgoECqVavmkcfwT4UBfNmyZfLll1/KDTfcIAMGDJAVK1bII488Ivn5+fL5559Lu3btJC8vT2JiYmT+/PmyatUqadeunae7j1Latm2b9O7dWwYOHChfffWViJT9iGvR9latWiV///23eHt7y+DBg6VevXqM8MJS2BMBVBq33nqr3HLLLSJy+sP4xIkT8vvvv8tvv/0m+/btk2rVqkmNGjWMA6xeeeUVCQkJkdmzZ8sXX3zh9uFcmsBq1hiAzWaTL774QsaOHSt+fn7StGlTERG58sorZdKkSeLl5SUjR46UUaNGyciRI+Wdd96RxYsXE1gruJYtW8qcOXNky5YtMmLECBEp+xHXoifZmDx5sjz//PPy5ptvSseOHWXv3r0EVliLAkAl4HK5dP369Zqbm6uqqk6nU1VVd+zYodHR0VqzZk19+umnjdsXbldVff311zU/P/+C6hcUFBj/f+zYMd2/f3+x/pXWpk2btEWLFvr++++71Sus8dtvv+nTTz+t119/vT733HO6ffv2UteCNRTdn7744gtt166d3nDDDSVuL42i++Pbb7+tjRs31nXr1qmq6htvvKE2m02/+OKLEm8PnKuS9psL2Xc5EKuS0iLz+YCqwGazSVBQkIiIzJkzR55++mn5448/pF27djJp0iRRVZk7d67UqFFDpk6daoy42u12ufvuu0Wk9FMCiv6E+uSTT8o333wjmzdvlrFjx8q1114rQ4YMEZvNVurXZVpamjRr1kwGDx4sOTk5MnfuXFmwYIHs379fOnbsKHPnzpXp06efd7uwrsL9ZM2aNfLtt99KrVq15MMPP5S8vDz5+OOPjRHX8x0J3bBhg1x66aUi8n+fE1u2bJF77rlHevXqJYsWLZKpU6fKW2+9Jddcc41kZWWJl5eX1KpVq8wfIyqvwn2rcD9OS0uTlJQU6d69+wWN3jPuX8no//95snBH+fvvv2XTpk2cKQeV2j9/Lg0MDBSHwyFXXHGFZGZmSqtWreS2226TUaNGyXvvvScvv/yyiIjY7Xa3+5V2Dmvhm/Bjjz0ms2fPloiICPnqq6/kxx9/lNjYWPn0009FRIzg+m8Kb1NQUCAiInl5eXLo0CF5+umnpUePHrJ06VK59NJLZdq0aZKcnCwrV64sVb9hXTabTZYvXy5DhgyRtm3bSnR0tNx///2SkJAg11xzjYic/1SBN998U3r16iXLli1z+/J09OhRyc3NlaVLl8pNN90kL774otx+++3icrlk/vz58uabbxr7IvBvin45z8/Pl7feektuvPFG6dmzp7zxxhsX3DgqiaJD7jk5OTp79mwdMmSINmzYUN9++20P9gwV0fr16zUjI8PT3fhXRff7jRs3Gn1OSEjQXr16aY8ePYzrdu7cqdOmTdP69evrhx9+WKb9WL16tXbu3FnXrl2rqqo//fST1qhRQzt16qR9+vQ5759a165dq/379zf6PmvWLL3llls0KipKt23bpqqq+fn52qtXL12yZEmZPhZ4Xl5ent5+++16yy23GNedOnVKP/roI23SpImGh4cb15/rz63btm3TO+64Q+vXr6/x8fGqenpffPnll7VHjx5at25dnTVrlnH7o0eP6tChQ92m1QDn4uTJk/rYY49pWFiYNmvWTG+55RZt2bKl/vzzzxfULqG1ksnOztaoqCgdNmyYNm3aVCdMmKDNmjXThIQET3cNFYTL5dIffvhBbTabvvrqq5qZmenpLp1R0Q/rRx55RLt3765Lly7V/Px8LSgo0DVr1uill17qFly3bt2qb7zxxgXPYf2nbdu26f/+9z9VVf3666+1QYMGGhcXp3/99Zc2atRI//Of/+icOXPOub3NmzdrkyZNdODAgXry5ElVPf36LuqRRx7RVq1a6d69e8vugcAy/vvf/+qgQYPcrsvOztbJkyerzWbTq6666rzb3LVrl06aNEkdDod+9dVXqnp6DnZwcLD6+/vrqlWr9NixY7pr1y4dOnSo9urVS/Py8srk8aDyW79+vT777LPaqlUr7devnz7zzDPqdDr1tttu05CQkAueG01orSR++OEHjY2N1cDAQO3bt6+++OKLmp2drZGRkRoaGurp7qECiomJ0Ro1auhrr71m+RHX6dOna7NmzXTZsmV67Ngx4/rCAN6zZ08NCgrStLQ0t/uVNriWNLJ16tQpPXbsmGZnZ+uwYcM0JibGuF1ISIj6+fnpgw8+eE7tF76xJycna9u2bXXAgAGanp5ubH/vvfd00qRJ2rhxY924cWOpHgOs791339XevXvrqlWr3K5/5513tFevXtqnTx/dt2/febe7Y8cOI7guXrxYVVX//vtv7datm3bp0kV9fX01ODhYg4ODjQMby/pLHiqfRYsWqb+/v15zzTX6zDPPqMvlUpfLpRs3btRLLrnEONDvQg7EIrRWcC6XS3/88Ue12Wx63XXXaWxsrLHt999/1x49euj333+vqrzp4NwUHVV5+umntXr16vrGG28UC3xWsWXLFm3fvr0uXbpUVVXT0tJ069at+tZbbxm/MPz000/asmVLnThxoqpe2JHQ/5yO8Mcff7gF5aysLO3Ro4e+8MILqnp6qs6ECRN06dKl//pmnZSUZPx/YR83b96sbdu21ZCQEONvMH/+fJ0wYYJu2bKl1I8DpWPGUfSFbe7evVs3btyoycnJmpubq3/99Zf26dNHx4wZoytXrjRuP3XqVH3wwQc1KyvrX9s+0z63e/duve2229ThcOiiRYtUVTU9PV2///57nTdvnv7444/GZwYjrTgXhw8f1h9++KHYZ8Vzzz2ngwYN0gMHDlxwDUJrJbF+/XrjJ8RCzz77rA4cOFD/+usvD/UKFVHhB+jq1at18eLFWr9+fa1Xr57OnDnTklMFNm3apO3bt9fvvvtOv/vuO508ebJ27dpVW7RooZdccokuXrxYXS6XbtiwoUy/uD388MPaqFEjbdmypbZq1Up///13VVU9cuSIXnHFFfrf//5Xn3zySR08eLD27NnTCA9nChHHjh3TevXq6dVXX21cV/i3SExM1Pr16+vo0aONUe9Tp06V2WPBuSn6tzt69GiZ7E+Ff+MvvvhCW7Vqpd26ddMWLVroddddp5s3b9Y//vhD+/btq5deeqn26dNHhw8frrVr19bk5OTz6u/8+fP11Vdf1eeff14PHDigLpdLDx48aATXM82LZrAD/2bPnj1nDKSbN29WX19fnTt3bpnUIrRWYHv27NG///67xG1btmzRhg0b6rx588q5V6VT+MZt1dG8qqDoCFJ8fLx6e3vrCy+8oM8++6zedNNNWq1aNX3ttdc8GlxLCnz5+fnarVs3vfjii7V69eoaGRmpX331lR44cEC7du3qdmBJ4e1Lo+jzs3btWg0MDNRVq1bp8uXLdezYserr66urV69WVdVff/1VhwwZov369dOrr77a+In1bCOtBQUFumzZMm3atKmOHTvWbdvJkyd14MCBarPZ9Morr2TNTA9ISUnR6OhoVVX9/PPPtXfv3md8/z1fa9euVYfDYeyrc+bMUS8vL509e7aqqm7fvl0/+eQTvemmm3Tq1Km6efPmf22z6D7y4IMPqq+vrw4YMEAbNmyonTp10nfeeUdzc3P1wIEDOmnSJG3YsKF+/vnnZfJ4UHUsWrRI+/btq6+//rrbyH/he92LL76o11xzTZl9bhBaK6jFixdrx44ddf78+XrixAnj+sI3qtdee01Hjhzp9rOlVRX2edmyZRoWFqa//vqrh3tUtRT9hlxQUKC5ubl65ZVXakREhNvtHn30UfX29taZM2d65MtF0cD3yy+/6A8//OA29WXJkiXGvwv169fPODiqrILerFmzdNasWfr8888b12VmZupNN92kderUMYJrenq6njp1yqj7z59YS+pPXl6efvPNN9qgQYNiwfWee+7RlStX6u7du8vkceDcuVwufeGFF7Rbt2763//+V729vctk5Khwn37sscf0+uuvV1XVvXv3aps2bdxef0XnlJ/vfMBDhw7pgAEDNDExUfPy8tTlcukNN9ygQUFBumDBAlU9Pcf1uuuu0yFDhlzoQ0IVsnjxYvXx8dEZM2YUO5mK6un35UsvvdT4slcWCK0V0JIlS7R27dr68ssvlzgJ/9SpUxoQEHDOB314StEP7YULF2qdOnX0ySefNEJrWY4mFX2jv9AzyVQmb7zxhg4aNEh/+eUX4zqn06kDBw403mgKRwlVVceOHatNmjTRl19+2WMjrlOnTtWAgAANDAxUu92u48aNM5aAUj0dIFNTU3Xo0KHavXv3C56PV3Q/TE9P1+DgYLXZbBoZGem2vTC4OhwO/frrr93a+Oc+V3ifn376SWfOnKmPPPKI7ty509j+9ddfa8OGDTUsLEzff/99veeeezQwMFAPHjx4QY8FF+bGG280RrsLlWbkvvDvX/hBP2XKFH3uuec0MzNTW7RooREREcZtFi9erPPnz9ecnJzzrvPCCy9o79699corr3QbwMjNzdURI0Zor169jOv++usv3huLKHz+MzIy9MiRIyVuq8oOHjyovXr10tdff11VT8/dP3r0qH722WfGwaHHjh3TqVOnGmcfLIvnjdBawRw7dkz79OljrJuXk5Ojx48f108//dRYH1JV3YbqrfYC++fcl+3bt2tgYKC+8cYbbtdfyEEmhW++WVlZxofKha4PVxn99NNP2qpVKx07dqzbCPfkyZO1TZs2xhHrhcE1KipKGzZsqI0bN9bjx4+Xe3//97//aaNGjfTnn3/WHTt26Nq1a9Xf31//+9//6q5du1T19L7fs2dPHThwoClHPu/atUuvvfZabdy4sW7dulVV/+81lpWVpcOHD9fBgwef8f6Ft124cKE2atRIBw4cqAMGDFBfX1/95JNPjLmqSUlJ2r17d+3SpYt27txZf/vttzJ7DDh3Rd8/H3jgAR07dqz2799f7733XuM4gtLsXwsWLNB69erpgQMH9LnnntP69etrs2bN9L777jO+aBUUFOiECRP0nnvuOe/Q6nK59JNPPtHmzZtrs2bNjC88hQFi27ZtWqNGDf3hhx/c7kdw/b+/+ZIlSzQkJEQDAwP16quv1pdeeom55P9fRkaGdu/eXd944w3Nzs7WRx55RPv376/NmjVTb29vYx3gwn25rHIIobWCOXr0qPbp00fnzZune/fu1UceeURDQ0O1Vq1aeumll+prr72mqu6jY1by/vvv69VXX+0WIFetWqUXX3yxqp7+0J89e7aGhoZqjRo1dOzYsaUORykpKXr11Vfrr7/+qh9//LHabDb97rvvyuRxVAaFH06JiYnarl07HT16tP7000+qqvrnn39qnz59NCwszO2nyQcffFC/+eYbPXr0qEf6fOutt+qtt96qqv/X/z///FPr16+vU6dOVdXTI55z58694COfi354x8bG6pQpU4zX1d69e3XQoEHavHlzIywXvilnZ2f/6wf/Dz/8oE2aNNH33ntPVU+P4NpsNm3YsKHOmTPHCEMFBQV6+PDhCj/Xu6IezFP4N/3xxx81MTHRuP6JJ57QPn36uAVXVdXU1NSz/u2LfrmZPHmyvvLKK6p6+v16zJgxWrt2bU1NTVXV07+YRUdHq5+fn/Hl6GzOtAzbl19+qQ6HQ2+88Ua3bRs2bHA7gBDuli1bprVq1dLnnntON23apOPHj9eGDRvqihUrPN01Szh69KhOmDBBu3fvrnXq1NERI0bozJkz9dChQzp06FCdOHGiKQNmhNYKaMiQIdq6dWutU6eOjho1St944w1NTU3VwYMH67333uvp7p3VJ598oj169NAbbrjB+El6//792rhxYx0yZIh26dJFR4wYodHR0fr999+rzWYz5l2dr4MHD2qXLl20a9euWr16dX3//fdVlZGEQkXfUH7++Wdt166djho1yvhwXrJkifbp00dbtmypd9xxh44YMUJ9fHw8ssxSQUGBFhQUaFhYmI4fP97of+Ho06xZs7RNmzZ6+PBht/uVxTqsmzZtMhZzf/75541thcG1RYsWxjzTos/pmfaz3NxcfeONN/SRRx5R1dMHVAYGBur999+vd955p9auXVvnzp3rNle9Ivv666/1nnvuqXCP558j4nfddZcRKLOzszUmJkb79u2rd999t6alpeljjz2m/fr1+9dlqH788Uft0qWLXnbZZW6B8aefftL+/furr6+v9u/fXy+77DL18/M7p3V4i+5rP/30k65cudJt+s4XX3yhderU0TFjxujy5cv1559/1mHDhmlQUFCF/UJhloKCAj116pSOHj1aH3/8cVU9fYCwv7+/3n333W63q2r27dunf/zxh/E+e+jQIV28eLG+9957bl/eRo0apY8++qgpfSC0VgA7d+7U5ORkt3mHCxYs0AULFmhOTo7xpnP99dfrfffdpwUFBRf8Dafw/rt27dJt27YZiwKXhSVLlmivXr30+uuvNx7Tt99+q+PGjdPHHntMd+7caYyODRo0SBcuXHjeNQrfUD7++GOtVq2atm/fXr///nvjeqtNmfCUrVu3GkdAFwbXa665xlgvdNeuXfrAAw/oyJEjNTw8XP/4449y6deZPhDeffddrVmzpi5btszt+jfffFN79+5d7IxRF2rq1KnaoUMHnTRpkvbq1UttNps++uijxv6zd+9eHTJkiHp5eZ11abl/7m+///67JiUlaVZWloaGhuptt92mqqe/aPn6+qrNZtP58+eX6WPxhM8//1zr1aun99xzT4Uc0fvmm2+0Vq1a+v777xdbUtDpdOoLL7ygXbp00cDAQG3WrJnbe/TZ2uzRo4fWqlVLd+zY4bbt1KlTOnv2bH3iiSf07bffPu+D7h566CF1OBzq5+enfn5+unTpUuO99IsvvtBGjRqpzWbT+++/XydMmGB86SO4FjdkyBBdvXq17t+/X5s3b66TJk0ytn311VdV7oDhhQsXauvWrbVly5basGFDvf7664vlgiNHjui0adO0UaNGpg1uEFot7vPPP9dWrVoZI6vDhw8vttzJiRMnjPOpl8WOUnTdwI4dO2qXLl20adOmOm7cON2+ffsFt6t6epmMXr16aXh4uG7YsKHE2z766KPavHlzTUlJKXXNpUuX6gcffKDBwcE6cOBAXbFihdGPcxkVq8x27typQUFBetdddxkHGhQNrkV/DnW5XOX2HBWt8+OPP2p8fLxu27ZNMzIy1Ol06oQJE7Rdu3b65Zdfal5enh4/flyHDh2qo0aNKtMvI0uXLtW6desaU1kyMzN19uzZ6uXlpY899pjxQb9792699957z/jBX3Td21deecUtWCcnJ2u3bt2MVQ927typkyZN0vvuu0///PPPMnssnrBx40Zt0KCBvvvuu27XZ2VllenfqaTXc1nIz8/X++67T++66y5VPT2Hb926dRoZGamPP/64bt68WQsKCnTdunX6ySefnDFgFj1xQOG80lWrVmnHjh21e/fuxpST0kxjKfrYf/vtN+3Ro4d+9913umPHDp0wYYLWrl1bP/74Y6PtJUuWaJMmTYwpNqpaqgO8KrP8/HzNzc3V0NBQvfnmm7Vdu3Y6adIk4zk8evSojh07Vt95550qM/jx/fffa61atXTGjBn6559/6rvvvqvDhg3T/v37G++PCxcu1IkTJ2pgYKCpZ+kjtFrYDz/8oHXq1NF3331XExMT9ZdfftG2bdtqaGioMRK2aNEivfzyy7Vt27ZluqOsXr1a69Spo++8845mZWXp8uXL1Waz6SeffFJmNRYuXKhBQUEaHh5uzKVUPR0Wrr/+em3WrNl5P6YzvYkcOHBAe/furf/5z3/066+/Nm5X1dclfPjhh7V///76wAMPGCOuv/zyi1500UU6ZswY44xSnvDAAw9o06ZNtX79+tq+fXsdOnSoHjx4UA8dOqQRERFarVo1bdeunbZv397tw7+sPkg+/PBD7dixY7HR25dfflltNpu+8MILxUbuzxRcP//8c61fv77eeeedbl8sV69erXa7Xb/55hs9fvy4PvbYYzp48OBKcQaijz/+WC+77DJVPX0A6UcffaTDhg3T9u3b63PPPed2WtrSKHp0d35+vvFzeFl+uRo7dqxeeumlumvXLh0/frxeccUV2rt3b23VqpWOHj36X2sVHQDo0qWLzpo1S48dO6b5+fn67bffateuXTU4ONgIjoUHSRW975kUre10OnXbtm3Gz9mFbrvtNq1Vq5ZbcF20aJHWqVOn2JJ2VVXh83z8+HEtKCgwnqdVq1ZpgwYNtHv37m63nz59urZr165KLD1X+Nw89thj+t///tdt2+rVqzUsLMz4lWjTpk2l+nXgfBFaLeyFF17Q0NBQt5/7Dx06pK1atdLw8HBVPf0h+eabbxoHg5SVmJgYveOOO1T19OhP4bfN0ijse1JSki5btkzff/994wjM+Ph47dWrl44bN874ae2rr77S+++//7xHjQvrrFmzRp944gm98cYbde3atcboxoEDB7RPnz4aGhqq//vf//SRRx5Rm81WJd58VM88IvX4449r79699YEHHjBGXNetW6cNGzbUm266qcx/cv+3/qmePgiiU6dOmpCQoPv379cPP/xQr7jiCu3Ro4ceOnRIVU/P3ZszZ45+9tlnppxucuXKlWqz2YwR58KQ8Ntvv2mtWrXUZrPpc88996/t/Pbbb9q4cWN95513Stx+3XXXqc1m006dOmn9+vVL/OWhIlq6dKkR7vv166fDhw/XyZMn69SpU7Vu3boXNNWkcF9ZunSpjhw5Uvv06aMjR47Ub7755oLbLGrz5s3aunVr9fX11TFjxujixYtVVfXTTz/Vrl27ntM62MuXL9eaNWvqa6+95rZkWX5+vq5cuVK7d++uAwYMOK8Rz6J9feKJJ3Tw4MHapEkTHTJkSLGDJG+//Xb19fXV9957z5gbvmTJErXZbHrPPfecc83KbPHixRocHKxBQUH6/PPPG9M2Xn75ZfXy8tIxY8bo5MmT9cYbb9R69eqZOpJoRY8++qgGBQUVm6/92muvua0kUx6/xhFaLez+++93W0evMDysXr1a69Wrp5s2bTKlrsvl0quuukqnTZumOTk52qJFC500aZLxRjlz5kz99NNPz6vNzz//XAMCAjQoKEgvueQS9fPzM47CLJzjesMNNxhzZIqOOJyPL774QuvWravjxo3TQYMGaefOnXXatGlGMD148KAOHTpU+/Tpox06dKhybz4///yzvvjii8WWbXn88ce1S5cu+tBDDxkfeomJiW5rh5aXjz/+WO+9995iH6hr167VAQMGaGRkZIn7R1kcdFXU8ePH9b///a8OGjTIbbmpvXv36l133aWvv/66ent7uy01V5LPP/9cBwwYoOnp6UYf/1lz/vz5+tFHH5X5l09Pi42N1W7dumlkZKRbGO/Ro8e/Pm//ZsmSJerj46OxsbH60Ucf6fjx49Vms7mt2XuuCt/bfv31V50xY4bOnj1bV65cqaqn55n+833igQce0LCwsLOuVVxQUKDZ2dk6YsQIY2WLQoVfrvLz83XNmjUaEBBwzgv7F9133n33Xa1fv77GxMToVVddZazf/c8wPXr0aL388suNx1lQUKBLly71yEGVVpOUlKQNGzbUp59+Wm+66SYNDg7WMWPGGMH1m2++0WHDhumIESP03nvvrZLP2fvvv6+NGzfWNWvWFDuA9+KLLy7XgR9Cq8WkpKQYoWHNmjVqt9s1Li7O7TarV6/Wdu3a6d69e03rx9y5c3XAgAHaqFEjnTx5stub3a233qp33XXXOY8M/PLLL9qgQQNjeZ/U1FS12WzGci+qp7/pXnTRRXrrrbeWemTvl19+0YCAAJ0zZ46qnp6DaLfbtW3btvrAAw8Yc2MzMzN13759Hlu2yVNcLpfeeuut2qlTJ3311VeLBdexY8dqs2bN9I477ii2mHZ5ycvL0969e6vNZtPLL7+82PaHH35Yu3XrVmajv0UDwJdffqkffPCB24jo0qVL9corr9RLL71UP/74Y/366681LCxMhw4dqn/99Ze2bt3aONXmmbz88svaoEEDt7U3C61fv96yy9Odr7Vr1+ozzzyj9913n65Zs8bYv/65akB0dLRedNFFF3SihKysLB02bJi++OKLqnp6YfzAwMBS/xqkevrLReGR+126dNFq1arpQw895Habn3/+WadOnaoOh8OYonU2BQUF2r17d33ppZeMfxdV+KtBQkLCeX9h+emnn3Ty5Mm6aNEi47p77rlH27Rpo6+99lqxpQLNOgh16dKlFW4fLvocfP/993rfffcZ/54/f76GhobqqFGjNDk5WVW1xNduZbZp0yZNSEhwmw547bXXavPmzfXbb781vhTdf//92qVLl3JdGYTQaiGLFy82TjuZlZWlaWlpOmXKFG3Tpo2xXFPhIr5dunQpk2BROPKzf/9+3bp1q/Fi3rhxow4cOFA7depkzDfNysrS6dOna/Pmzc9rNGP+/PnGKSkLTyRQ0ofLV199dUHf2L744gtjya/du3dr69at9Y477tDHH39ca9eurVOnTvXIyKGVZGdna0REhPbq1UtfeukltyOiX3vtNW3Xrp2OGDHC+DA1y9kOnsnOztbRo0drs2bN9IMPPnAL1wsXLtTOnTsXO0FFaRT9AHr44Ye1efPm2q9fP23cuLEOGjTIOOBxzZo1euutt2qNGjW0Q4cO2q9fP+NDrHv37jpv3ryz1vnxxx+1Xbt2+sYbbxg/r+Xn56vL5dJx48YVO6lGRbRw4ULjF44+ffpo//799aGHHnJb4/err77SW265RRs1anTBv3AcP35cW7Vqpb/88ov+/fffxq9BhebOnXteIXD79u3arFkz4wvIsWPHdP78+VqzZk1jabKtW7fqnXfeqT169DivlRC6d++uEyZMMP5duN/t2bNHX3nlFWMu+flYs2aNtm3bVhs1alRsdZXC4Dpz5sxiX8zLOnQ9+OCD2r59+7OunFGWyqL/he8533//vc6cOVOjo6P1/vvvd7tNYXAdM2aM268sVeHAq8JfRXv37q1+fn7as2dP4ziQESNGqJ+fn1588cUaGhqq9evXL/dfKwmtFlH0HL5FT826d+9effDBB7V69erasWNHDQoK0oYNG17QjjJ79mxdvXq18cH72WefaUBAgAYEBGjnzp11zZo1qnr6G3S/fv20TZs2OmDAAL388svPed3AoqZNm6aDBw/W48ePa8uWLXXSpEnGm8/cuXOL/XRWWgcOHNBt27ap0+nUoUOH6i233GJsa9u2rfr5+en06dMrxUEu56LoPOhjx44ZI/M5OTnGEk4vvviiEaSio6N11qxZpfoQPVv9pKQkXbp0qX788cdu+3bRn/Pz8/Pd/i6nTp3SwYMHa/fu3fX111/XgwcP6t69e/Wyyy7TwYMHl+mHx8svv6zNmzc35q4uWLBAbTab9uvXz23e5Z49e/Tw4cNG7YceekjbtGljPK//fLwLFizQgwcPqsvl0vHjx2vv3r319ddf18zMTD1w4IA+8sgj2qxZs1L9nG0lP/30k/r7+xurBKSkpGjt2rX14osv1rvvvlszMzM1Ly9P33nnHbfRqwuRn5+v119/vT733HPasmVLjYiIMPanw4cP64033qgfffTROe8nP/30k7Zv377Y+dM/+OADrVmzpv7888+an5+vO3bsOOMXujPVmj9/vjZp0kSfffZZt+unTp2qvXv3PqdffEpq+8knn9RmzZrp+PHji41a33fffVqrVi397LPP/rXt0vr999+1adOmximLi742ylLRUx4vXLiwTH4hW7Rokfr4+GjHjh3V4XBo48aNi+2XH330kfbo0UNvvPHGUk9Xq2h+/vlnbdCggfHr7o4dO9Rms+n//vc/4zaff/65vvrqq/rqq696ZBCI0GoBBw4c0J49e+rMmTNV9f/O4bto0SJjXs3PP/+szz77rL7zzjul3lEKX/zt27fXli1b6k8//aR//PGHtm7dWl988UVds2aNhoWFqb+/v3FU/aZNm/SDDz7QO++8U996661S1U5KStI+ffpo3bp1jSMNC0Pr/fffr2PGjHEbkfk3haNUqqefq3+G0L1792rnzp31q6++UtXT81jHjBmjUVFRF7R8VkVS+PwsWrRIe/Tooe3atdO2bdvqU089paqn5wzfeeed2rt3b+3WrZtee+21Ja4beaEWLlxojFwGBAToZZddpq+//rrb3/uVV17RG264QXv37q0fffSRsY+dOnVKw8LCtEaNGtq6dWsdNWqUDhs2zJiWUtpRl6+//to4YUVaWprecccdxpqoCxcu1Hr16unLL7+sbdu21f79++v69evdAvaPP/6od955Z4kjhv98vP/5z3903rx5mpubqxMmTNCuXbuq3W7XSy+9VFu0aFHh51Tn5OTol19+aXxB3L17t7Zp00YnTpyoDz30kDZq1EgfeughY+7n2eaAluRsr/UHHnhAbTabXnXVVW5TlaKiorRDhw7nNX1q/fr16uXlZXxhL6yZmpqqrVu31o8++uis9y+8fUJCgsbGxurkyZN1w4YN6nQ69cSJE/rYY49pkyZNdMyYMfrwww/rDTfcoA6H45xOzVt0Py8oKHA7GOapp57SSy65RKdNm1YsTM+YMcPU9VeTkpK0U6dOumLFCo2Li9Orr766zH+hKXqCh3r16ulTTz1Vqs+gomH6xIkT+vjjj+ucOXOMg9IGDRqkwcHBxZaT/PTTT6vMZ4aq6ltvvaXXXHONqp7+ZaFNmzbGZ7bL5bLEgA+h1cNcLpeeOHFCu3btqu+99546nU597LHHtH///tq4cWO12+26atWqC67zzw/4kJAQ7dChg37wwQfFRjpHjx5tBNdz/YbpcrmMN4bk5GRdvny5fv3117pnzx7Ny8vTSZMmadu2bXXWrFmqenoO2vTp07VRo0bnPPLyz+WXvvrqKw0LC9OrrrpKn3/+eeP6zZs3a4cOHfSll17SnTt3akxMjP7nP/+54CV2KpqVK1eq3W7X1157TT/88EOdMWOGent7GwHD6XTqvHnz9I477tBbbrml2Bv2hVq/fr02adJE3377bVU9PVJis9n0uuuu0yeffFJVT/8s37hxY33yySf1nnvu0Xbt2mlkZKTRl1OnTunIkSM1ICBA33vvPWMua2lHPn744Qe12WwaFBSkH374oaqeXtrm0KFD+ttvv2nbtm2NUyHPnTvXOKq/6Gjo3r179bXXXiu2ZvGZHm/hCFteXp7u2LFD4+Li9Ouvv3Ybda6IEhMT9a677tL9+/frtm3bNCcnRwcNGqQTJ05U1dN/o1atWmnTpk31wQcfPK9RuLO91mNjY43rx4wZo35+fnr//ffrM888o7fccsu/hsHCfvz555+6du1a3b17txYUFOiIESP02muvdbtvTk6O9uzZUz/44IN/7fMXX3yh9erV06uuukqvuOIKbdy4sb788suanp6up06d0q+++kovu+wyHTRokI4fP/6cXm9F37dnzJih11xzjQ4YMEDvu+8+I7w+/vjj2qNHjxKDq6q5Jw4IDw/XVq1aqc1mM6a5lPVo6+rVq9XhcOicOXPcQtO5vAf88yQkGzZs0KZNm2qfPn3cTgSxfPly4wDdsvgloKIpfF994IEH9Prrr9f8/Hz19/d3OwB7/vz5+uqrr5q2LvK5IrR6UFxcnM6YMUNPnDih48eP1549e6qvr6+OGDFCZ8yYoQcOHNDLL7/c+KZTWkXnUM2cOdP4plp4wEtYWFixifSjR4/Wtm3b6vz588960Ms/R0gXLlyofn5+2q9fP+3QoYMGBwfr4sWL9dChQxoeHq7t2rXTxo0ba+/evbVNmzbnPNKUlJSkNptNp02bpqqn53TVrFlTJ02apDfddJPa7Xa3BbMjIyO1ZcuW2rJlS23atGmFWkao6EL+pXljKLzP5MmT9frrr3fbtmbNGvXy8nIL+aplu1RUoffee0+vuOIKVT29bFrr1q11wIABarPZdNWqVfrWW29pmzZtjJ/lC0Ne4fJqhUfpnjp1Si+77DINCgrSxYsXX9BBWIsXL1abzaYDBw7U4cOH68cff2xse/311/Xyyy83pkfMmzdP77rrLg0PDy/2wV/SKG9Jj/f22283tns6pF7ofvVPr776qnbt2tUIecnJydqhQwcjcO7bt09HjBihjz766Hk99nN5rRedIxoVFaXDhw/XSy+99Jy/fBWuVdquXTu12+06b948ffvtt/Wyyy7TESNG6LJly/TPP//Uhx9+WJs0aaJ79uw5a3s///yzNm/e3DjYNC8vT729vbV58+b69NNPF/tJ+3wPXIqKilI/Pz999tlndeHChcaXv8Lg9vjjjxsnCvnnAVhmKNyPPvvsM7XZbNqiRQtdvXp1mZ2owOVyGa+5KVOm6OjRo1VV9eTJk/r999/rbbfdphEREcYKNCX5+eeftV69esYUHdXTS/kNHz5ca9SoYZzQo9CKFSt0+PDh2r59+yq1QkBcXJzxRf3HH3/Utm3bau3atY2TahS66667dNy4cf96mmKzEVo95MCBA9q1a1d95plnVPX0z/Cff/65vvvuu24/oY0cOVKfeOKJUtcpfHP5448/9OKLL9ZrrrnG7WjTwYMHa/369XXVqlXFPpgHDx6sl1xyyRl/ur/99tv1lltuMe7366+/aoMGDYz5L8uWLdNq1aoZo2pHjhzRTZs26euvv66rVq0yzuN9LnJycvTtt99WHx8fjYmJ0S+//FJffvllVT39AbFixQr19fXVm266ybjPt99+q19//bXlf94p/BsVfcMvzc/0hW/MhW8qV155pY4bN87YVvgB98wzz+gll1yiR44cMf52ZnxrnjVrlk6cOFFPnTql/v7+GhoaqtWrV9elS5fqsmXLdOLEica+vXjxYq1Xr56+//77OmvWLLXb7Tp58mTjS82pU6d06NCh2rZtW2PaR2ndeOONGhISoqNGjdLQ0FCdO3euqp6e03vxxRfrwYMHNT09Xa+++mrjlwHVfx+x+ufjLTp3e9myZfrSSy+V62h/We1X/1T0wLiBAwfqwIEDVfX0XNaLL75YY2Nj9ciRI/r4448bc9nPx7m+1m+44QbjPnl5eW6ntD6TgoICPXbsmPbv31/feust3bFjhz711FPq7e2t//vf//Sdd97R6667Tr28vLRDhw7arl27c/piPX/+fH344YdV9fQUiVatWuk999yj0dHRWq1aNX3uuefc3ofO58QBv/32m7Zv396YupCQkKA+Pj7F1v295557dOLEieU6AvbJJ5/o3Llz9eqrr9Z27drpV199VapfQUraVwt/yXjooYc0JCREP/30Uw0PDzdGREePHq3dunU740FgTqfTOMq96C8lGzZs0CFDhmjTpk1169atbvf58ssvdcyYMf/6JaWyKMwhhb8GHThwQCdPnqxt2rQxfl04dOiQTps2TRs3bmyJs/QRWstZ4Ytz9erV2qtXL7czQRV19OhRY0f55wvrfG3ZskXr16+vUVFRJb7A+/fvr61atdLvv/++2AjSmYLlggULtHHjxm5v6O+++64OHTpUVU+P6rZq1co4QYHq+Y80lTSa9eabb6qPj482btzYbcks1dPflOvWrWv8PGkGs843vXPnTo2MjNRDhw4Zoxfn822/8INq5cqV+sADD+jevXv1jTfe0GbNmun69evdbjN79mzt1q1bsSWvSqvoqMjRo0eNL10bN25Um82mdrtdr7zySrXZbDp48GBVVb3jjjt0+PDhunv3bj18+LD26dPHWBbo1KlTxrncX3zxRWMU+NSpU3rNNdeUeoWJwg/E+fPn6+23366//PKLjho1Sv/zn//oV199pYcPHzbO2d6mTRvt2rVriSNi5/J4p0yZ4hYe7rjjDh07dux5z+m8UBe6X/3TihUr9IYbbjAOvtm7d6+2a9dOn3nmGXW5XBoZGalt27bVgICA8/qFo7Sv9aIHW55N4d8iOztbT506pdOmTXML06+88op6e3vrjBkz9PDhw7pz5079888/9fDhw2dtLykpSf/66y/dv3+/Jicna3Z2tg4ePNjtV58WLVpovXr19JVXXjmnn+qL7jf5+fn6/fffa7du3VT19BSEOnXq6Jtvvqmqp+dkL1mypNh9zQquhe3+/vvvunz5creVC0aMGGF8qSxNcC1pX/3rr7/0559/1uDgYA0ICNAbbrjB+Ml/4cKF2rdvX01LSzPaKGk/2rNnj3p7e+sDDzxgXLdhwwYdNmyYBgQEFPt89fRIYmmc7+fSP3NI4alYVU8/NzfddJPWr19f27Rpo0FBQdqqVSvLzL8ntHpInz593EYKilq4cKHefPPN2rJlywveUbKzs3XMmDHFhvpzc3N19+7dxk+hV155pbZs2VJ//PHHczrA5YUXXtAOHTqo6ulRsldffVXffvttnTRpkh48eFBbtGihERERRlvffPONvvjii25vMOdi3759xokMPvnkE73++ut1zpw56nA4Spw28c0336jNZiv2eMvCpk2b1GazGevAloWPP/5Yt23bpqtWrVJfX1+94oor1G63G99yz+fDZ+HChVqzZk198sknNTExUTdv3qzDhw/XYcOGGT/Bq55epiY0NPS8Dn4rydKlS93Wqly4cKH26dNH27Rpo//973913rx5GhcXp97e3mqz2fSWW27RZs2a6aWXXuo2lzk5OVnbtm2r3377raqe/vC6+eabdc6cOcaHfGnXgVy9erVxVHuhAwcOaIsWLfS9997TgwcP6qhRo3TAgAEaHx+vx48f19dff11nz55thOXC/57r4/Xx8dH58+er0+nUv/76S6Oios5r7nZZKMv9qpDL5dLbb79dbTabNmjQQB9//HHdvXu3PvPMMzp69GjduXOnnjx5Ur/99ltduHDheY9Wmf1aX7x4sYaFhWmnTp20Q4cOxZatevXVV7VGjRo6bdq0swaXogc5+vn56aOPPmosHbd7927t2rWrEaz279+vN9xwg06dOvWcRrlXr15tHBQYERGh9913n27ZskW7du2qTz/9tPr6+rotkfb999/rwIED3Va5MHuk9bPPPjNOb+rl5aVBQUHGrxUjRozQdu3a6dKlS885uJ5pXy26PvmRI0eML6uFjy8qKkr79+9fbI3QovvRggULdPz48fr6669rzZo1jSknqqfnZA8bNkzbtGlToeexXsjn0plyyN9//62//vqrvvjii/rVV1+Zuib8+SK0lqPCF9uyZcu0X79+bnOv0tLSdPv27bpkyRJdv369vvHGG2Vydpy8vDz9z3/+Y6xMoHp6lOK+++5TX19f9ff312uvvVZVTwdXh8PhNkH9TNatW6ft27fXyy+/XG02m37xxRf6xRdfqI+PjzZs2FDvvvtut9tPmjRJb7zxxvP6Fpubm6vh4eHar18/ve+++9Rms+n777+vLpdL58yZo9WrVzfWUCxq1apVFzw6/U9LlizR7OxsXbx4sdaqVcttCZDSSk1N1f79+xtvCM8++6zabDbt37+/2wf+uXwIbdu2rcSF7hcvXqzDhw/Xhg0b6rBhwzQsLEx9fX3P6ajlszl06JC2bt1ab775Zt21a5cmJydr3bp19emnn9bnnntOJ0+erD4+PhocHKw2m01FxBiB8/LyMqYtqJ6ee9ahQwd94okndOXKlXrVVVfpiBEjjMdd2gNJVq9erTabzZi3/cYbbxhnkVuwYIEOHz5cMzMzdfPmzTp69GgNCQkxDs4qVFj7XB9vRESEvvTSS2qz2bRt27bao0cPbdu2bbmOUpTlfvVPv/76q44bN06feeYZDQoK0jvuuENvu+027dixozFSXhpmv9bXr1+vvr6+escdd+jEiRO1evXqeu+99xabOvTcc89pvXr1/nVZpfj4eK1Zs6a+8847br9e/fHHH9q8eXP94IMPNCUlRWNiYnTgwIH/+quGy+XSjIwMHTx4sIaEhOjw4cPV19dXk5KSNCMjQ8PDw7VWrVo6ZcoU4z45OTk6fPhwHT16dLkter9x40Zt1KiRvvvuu3r8+HE9dOiQTpgwQYODg43XzrBhw7Rx48ZnnW9a6Fz31aJ++OEHnTp1qvH8FFV0P7r//vuN/Uj19C+B3t7ebsF148aNOmDAAO3SpYvm5uZWuHVYS/O5dLYccvz4cd2+fbuxuooVEVo9YMKECTpy5Ehj9GjVqlU6cuRIbd++vQ4cOFBzc3PL7MCY9PR07dChg95+++26detWffbZZ7V9+/Y6evRofe2113TOnDkaGBhoLIV0xRVXnPO8tzvvvFNtNpsGBwcb191zzz3q5eWlK1eu1LS0ND169KhxhHhp5sOcOHFC+/TpozabTSdPnmxcn52dbbwJlfRhVpYOHz6sISEh+uCDD2pOTo5++umn2qBBg/MeNS5J4YfZ5s2b9aabbtLnn39eAwMDdcKECWccPSnpjXXlypV68cUXGx/CRT/EtmzZovPnz9ebbrpJp02bVmYHGWzYsME4+GP69OluH6hpaWk6e/Zs9fHx0cjISGPptIULF+pzzz2njRo1cjtNa+F80sDAQO3Xr5/x2riQD5EdO3bowIED9fLLL9fQ0FC9++67tWHDhjpjxgx95ZVX9PLLLzcOxkhOTtbQ0NCzjtqdy+OtXbu2fvTRR8bjXbFiRbG1P8tDWe1XqqffnwrnTxYUFGhkZKTecsstmpGRobNnz9bbbrvN+HJQ9GfG82XWa33nzp362GOPua06MHv2bPX39y9xGbx/m4Nb+OtVYfg5efKk7tq1S5977jldtWqVDho0SBs2bGgcdHo+B4EeO3ZM27dvrzabTZ977jnj+q+//lr79OmjISEh+tJLL+ns2bN10KBBRthSLZ+zNX344YfaqVMnTU9Pd1sHevz48dq3b1/jdtdcc805L011Pvvqvn37dOzYsRocHHzGEzycy35UNLgmJSV5/CDJ0rjQz6Uz5ZAOHTpoSEiIZmRkWDLEE1rL2Xfffad+fn66bds2/eSTT/SWW27RWrVq6b333us2N6ksrVq1Sr29vTUwMFDr1q2rb775phFMc3NzdciQIW4jX+fi1KlTxsoGnTp10vDwcFU9/QZ+3XXXqd1u13bt2mnfvn01MDCw1CNNubm5evnll2v37t118ODBxk9nhX149913tWbNmsXOaFLWtmzZomPHjtXJkyer0+ks07mJaWlp2qdPH73xxhs1JydHv//+ew0ICNAJEya4fQtet27dGdtYtGiRBgQEuIXWwlHCNWvWmHZgwYYNG7R3794aGBhYLPCdOHFCb775Zg0PD3d780tPT9e33npLGzVq5HafzZs365YtW4wP37L44rZt2zYdNWqUDh8+XFeuXKkrVqzQUaNG6dChQ9Vms+nIkSON52nPnj3/+sF/ro/XCspiv8rPzzdGv2688Ub94Ycf1OVyac+ePY0DLNPT0zUyMlJbtGhxQQd6mfFaT09P16CgIG3UqJFbUFE9feBcixYtdPr06W7zpP/tg/rUqVMaFBSkd999tx47dkwjIyM1JCREmzVrpq1atdKZM2fql19+qUuWLDnv192JEyd02LBhOnDgQB08eLDxs7vq6dHde+65R/38/HTw4ME6ceLEYlNYzLZgwQJt27atcTKDwrp79uxRm81WbImpc3Wu++quXbs0Pz//jHONVc99Pyo8e2JFVtrPJU/kkLJCaC1nMTEx2qBBAw0KClJ/f3999NFHiy29Yca3m3379mliYmKxU78WFBTomDFj9JFHHtGCgoLz+rZeOI9rzpw52r59e73xxhuNbUuWLNH3339flyxZcl6rBJQkJydHDx48qFdddZVedtllxU6b+corr2jTpk3L7ExOZ7J582a94YYbzvqGWVrr1q3ToKAgveWWW/T48eP6ww8/aMuWLXXChAn6zTff6JNPPqk2m02PHDlS4v6xe/fuYnO2Ct1777362GOPmXZWl99//11btWqlHTp0KDbtYNq0adqtW7dic1ILg2vjxo2LTSVRLdtRo61bt+qVV16pQ4YM0S1btmh+fr4mJyfrrbfeavy8WPQ5/bfapXm8nnKh+1Wh33//XYcMGaL9+vXTe++9V5cvX64jRozQH3/80bhNWZx/3IzX+saNG/Wiiy7S/v37G9NDCr3xxhvq4+OjTzzxxHkFv8IzZfn6+uo111xjzBWOjIzUwYMHX/D+e/DgQR02bJhedtllbsFVVYs99vJc8H3nzp1qt9uLjXinpKRo165dz2lq2Zn82776xBNPqM1mM1YEOBurfGaUh9J8Lnkqh5QFQms5ysvL09tuu0379++vDz/8sJ44ccKjC/U6nU595JFHtHnz5sUWSj8fmZmZ+t5772n79u3Pe8T2fOzatctYuLvwjfyxxx7TCRMmnNMbWVkw83R+Gzdu1O7duxtv2j/99JN26dJFO3furIGBgcYqAGdSOPdv6tSpumnTJv3zzz/1oYce0nr16pm+7uAff/yhXbt21YkTJ7rNM5s0aZIOGjSoxLnM6enp+vbbb6vNZtNXX33V1P5t375dhwwZokOGDNG1a9e6bStNwCjN4/WUC92vCh06dEjnzp2r3bt319q1a2vr1q11+vTppvS5rF/rv//+u3bv3l0nTZpUbB3Xd999t1Tvf8nJyfrNN9+o6v/tQ3fddZcxWnihdu/erVdddZUOHjzYOChx4MCBxtJaqp753Jg/f77WqFFDo6KidMeOHXr48GGdPn26BgQEnHH5qXNVVvtqISt8ZpSH8/lcsloOOV+E1nKWlpbmtpOU1wT6f5o3b57ec8892rRp0zI5SCQrK0vfe+897dKliw4fPrwMeliy3bt36zXXXKNdunTRoKCgcz5wrKIo+qZ99OhRPXLkiG7YsOGc5kUWFBTop59+qvXr11d/f39t166dtm/fvtwOAtq4caN26dLFOI1nRESENmzY8KwHfZ04cUIXL15s6ll7Cm3fvl2vvPJKvfLKK4uNKpRGaR6vp1zIfvVPubm5ev/992v16tW1SZMmF7wKxZmU9Wt948aN2rNnT73tttvK/GjxLVu26LRp09ThcBQbzb0Qu3fv1lGjRmnHjh21TZs22qVLF1O/OJ8Ll8ulCxYs0Lp162rLli314osvVn9//zI7gUtZ7quq1vzMKO2yfWXFKjmkNAitHuSpbzVbt27V0NBQveaaa8p0seCsrCydPXu29u7d+4K/cZ/N/v37dc6cOfrEE0+U+SoBVrBx40YNCgrS6667zm1R7HP1119/6U8//aQ///xzmZ8L/N/88ccf2q5dOw0ICNDY2NjzOrFDefzMuX37dr3qqqs0KCjojAdynI8Lebzl7UL3K1X396yVK1ea/njL+rW+ceNG7d27t4aHh5fZrw+JiYk6btw47dixY7Gj2cvCgQMH9KuvvtJ333233Oewnk1KSoquWLFCly5desFTwP6pLPbVoqz0mbF69WqtVauWZeaOVoTR1aIIrVXU4cOHy+To9386efKkKe1WNevWrdOQkBA9cOCAp7ty3hITE3Xw4MGWnS/2559/6gMPPFBmowtWf7xFlcV+VdE+5P6prF9bp06d0rVr15bbEejl8auEFVTk98Cz2b9/v06aNOmCpuRVZTZVVQFgOTk5OeLj4+PpbpRKRem7y+USLy+vC26nojxekYrVV7PwHFQMlfXvlJ+fL97e3p7uRoVEaAUAAIDlXfgQAwAAAGAyQisAAAAsj9AKAAAAyyO0AgAAwPIIrRWI0+mUmJgYcTqdFbJ9alS9GpXhMVDDWjUqw2OghrVqVIbHUJlqnA2rB1QgGRkZ4nA4JD09XXx9fStc+9SoejUqw2OghrVqVIbHQA1r1agMj6Ey1TgbRloBAABgeYRWAAAAWB6nZPAQl8slBw4ckLp164rNZjun+2RkZLj9t6yZ3T41ql6NyvAYqGGtGpXhMVDDWjUqw2Owag1VlczMTGnevHmZnH2QOa0esn//fgkICPB0NwAAAEyVmpoq/v7+F9wOI60eUrduXRERCZ8wVWrUsJtWx691M9PaLlStenXTa+zbutfU9lO27TC1fRGRi7t2Mr1GrjPX9Br5eS7Ta1zUs63pNY7+dcz0Gns27Ta9Rud+XUxt/+Dug6a2LyJSw6eG6TXSj6abXiPnVI7pNdoHXWx6jaEjQ02v8fkHy0yvsX/HflPbz8w8bmr7IiI52Zmm1/Cubl4Gyc/Pk8TEZUbmuVCEVg8pnBJQo4ZdatTwMa2O3aemaW0X8q5hfmg18zkSEfH2LofHYDf3MYiIiJo/Td3LVmB6DZ+atUyvYbefNL1G9ermhzGzX+Nmv/ZERGrYzX+eqlc3P1AWVDf/C115vKfXrlPH9Brl8X5o9uuvPD43KkuNc50G+W84EAsAAACWR2gFAACA5RFaAQAAYHmEVgAAAFgeoRUAAACWR2gFAACA5RFaAQAAYHmVIrSeOHFCsrKyTK2Rk5MjR44cMbUGAAAASlZhQ2t+fr4sXbpUxowZI35+frJr1y7Jzc2VyMhI8fPzEx8fHwkMDJTY2FjjPvv27ZMRI0ZInTp1xNfXV8aOHSuHDx82tv/+++9y2WWXSd26dcXX11cuvfRSSUxMFBGRw4cPS4sWLWTkyJGyaNEiycvLK/fHDAAAUFVVuNC6adMmefDBB8Xf319uuukmady4saxZs0a6desmr7/+unz55Zfy6aefyrZt2+TDDz+UVq1aiYiIy+WSESNGyPHjxyUhIUFWrlwpu3fvluuuu85oe/z48eLv7y/r16+XDRs2SFRUlFT//6coDQwMlJ9//lkCAwMlIiJC/Pz85J577pENGzacU7+dTqdkZGS4XQAAAHBuKsRpXI8dOybz58+XDz74QJKTk2XYsGEye/Zsufrqq6VGjf87Tdu+ffvkoosukgEDBojNZpPAwEBj26pVq2TTpk2yZ88eCQgIEBGRuXPnSufOnWX9+vXSq1cv2bdvn0ydOlU6dOggIiIXXXSRWz8uvfRSufTSS+Xll1+W5cuXy9y5c6V///5y0UUXyYQJE+TGG2+Upk2blvgYYmNj5YknnijrpwYAAKBKqBAjrTNnzpT77rtP6tSpIzt37pRFixbJqFGj3AKriMjEiRMlKSlJ2rdvL/fcc4988803xrYtW7ZIQECAEVhFRDp16iT16tWTLVu2iIjIAw88ILfddpsMGjRInnvuOdm1a1eJ/fH29pbhw4fLZ599Jnv27JFmzZrJ1KlT3aYi/FN0dLSkp6cbl9TU1At5SgAAAKqUChFaJ02aJE899ZQcOnRIOnfuLDfffLOsXr1aXC6X2+169uwpe/bskaeeekqys7Nl7Nixcu21155znZiYGElOTparrrpKVq9eLZ06dZJFixYVu52qytq1a+X222+Xjh07ys6dO+Wxxx6TBx544Ixt2+128fX1dbsAAADg3FSI0Nq8eXN55JFHZPv27bJixQqpUaOGjBo1SgIDAyUqKkqSk5ON2/r6+sp1110n77zzjnzyySeycOFCOX78uHTs2FFSU1PdRjj//PNPSUtLk06dOhnXXXzxxXL//ffLN998I6NGjZL333/f2LZ9+3Z59NFHpU2bNnLVVVdJfn6+LF68WHbv3i1PPPGEtGzZsnyeEAAAgCqmQsxpLapfv37Sr18/ee2112Tx4sUSFxcnL730kvz222+ycuVK8fPzkx49eoiXl5d89tln0qxZM6lXr54MGjRIunbtKuPHj5cZM2ZIfn6+3HnnnRISEiJBQUGSnZ0tU6dOlWuvvVZat24t+/fvl/Xr18vo0aNF5PR82Y4dO0poaKg88cQTMnr0aKldu7aHnw0AAICqocKF1kI+Pj4SHh4u4eHhcuDAAalTp47UrVtXXnjhBdmxY4dUq1ZNevXqJcuWLRMvr9MDykuWLJG7775bBg4cKF5eXnLllVfKzJkzRUSkWrVqcuzYMbnpppvk8OHD0qhRIxk1apRx8FSjRo1kz549jKYCAAB4QIUNrUU1b95cRERuv/12uf322894u5YtW8qSJUtK3FajRg1ZsGDBGe9bq1YtAisAAICHVIg5rQAAAKjaCK0AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyKsXqARVZY//GYvepaVr7GcczTWu70N97D5teo/OALqa2n1kOz1PtenVMr/HL4uJncCtrLVpcbHoN/4svN71Gvab1Ta+x8/ftptfwqe1javvpR9NNbV9E5NoHz/3MhaX1zKSHTK/Rrl1P02sc3H3I9BrvvPiR6TWCwi41vcauTea+/mw2m6nti4i08L/I9Brp6UdNazs/P7dM22OkFQAAAJZHaAUAAIDlEVoBAABgeYRWAAAAWB6hFQAAAJZHaAUAAIDlEVoBAABgeYRWAAAAWN55nVwgISFBIiIixMfHfTFrl8slISEhsm7dOnE6ncXul5WVJcnJyTJjxgyZN2+eeHu7l83NzZXp06dL3759ZejQoVKrVq1ibbRu3VoWLVok11xzjezZs6fY9lOnTsny5cvll19+kWeeeUZq1Kjhtj0/P19uvPFGue+++6Rz585Sp07xhd7tdrv8+uuvcvfdd0tCQoJ4ebln+pycHHnrrbdERM76PMycObNY2wAAACi98wqt2dnZEh4eLjExMW7Xp6SkSFRUlNhsNklKSip2v9DQUFFVOXHihMyaNUtCQ0PdtsfFxUlmZqbk5eVJv379JC4urlgbffv2FRGRgwcPllhj4sSJkpeXJ5mZmfLQQw/JxIkT3bZ/9913smLFClFV8ff3l+++++6MNY4cOSJffvmltGrVym17TEyMZGdni4ic9XkAAABA2eI0ruXE6XS6jUJnZGR4sDcAAAAVC3Nay0lsbKw4HA7jEhAQ4OkuAQAAVBiE1nISHR0t6enpxiU1NdXTXQIAAKgwmB5QTux2u9jtdk93AwAAoEJipBUAAACWR2gFAACA5RFaAQAAYHmEVgAAAFgeoRUAAACWR2gFAACA5Z3XklcOh0Pi4+MlPj6+2LawsDBJS0uToKCgEu/r5eUl/v7+MmXKlBK3T5s2TWrWrCmbN28usY2uXbuKiEjHjh3PWKNmzZrSpEkTefbZZ2XWrFnFtk+cOFG8vLwkKyurxDYaNWokIiJt27aVa6+9tsQaYWFhIiJnfR4AAABQts4rtAYHB0tiYmKpi0VGRkpkZORZb/Nv7b///vtn3R4YGCijRo26oBrPPPOMPPPMMxfUBgAAAMoO0wMAAABgeYRWAAAAWB6ncfWwnOwcUZfNtPar16huWtuF6jWtb3qNg7sOmtp+k5ZNTG1fRGTzz0mm1/DxqVsONWqZXmPNgu9Mr+FyuUyv4Vu/nuk1flv1m6nt5+ScNLV9EZENKzeYXmPETTeZXuPoX0dNr3Ek9YjpNcZHjzO9xu/fbzK9RqsObUxt/+iBY6a2LyLif7G/6TXyN+Wb1nZenrNM22OkFQAAAJZHaAUAAIDlEVoBAABgeYRWAAAAWB6hFQAAAJZHaAUAAIDlEVoBAABgeVVyndaEhASJiIgQHx8ft+tdLpeEhITIunXrxOksvrZYVlaWJCcny4wZM2TevHni7e3+9OXm5sr06dNl/PjxpvYfAACgqqmSoTU7O1vCw8MlJibG7fqUlBSJiooSm80mSUlJxe4XGhoqqionTpyQWbNmSWhoqNv2uLg4yczMNK/jAAAAVRTTAwAAAGB5VXKk1ROcTqfblIOMjAwP9gYAAKBiYaS1nMTGxorD4TAuAQEBnu4SAABAhUFoLSfR0dGSnp5uXFJTUz3dJQAAgAqD6QHlxG63i91u93Q3AAAAKiRGWgEAAGB5hFYAAABYHqEVAAAAlkdoBQAAgOURWgEAAGB5VXL1AIfDIfHx8RIfH19sW1hYmKSlpUlQUFCJ9/Xy8hJ/f3+ZMmVKidunTZtWpn0FAABAFQ2twcHBkpiYWOr7R0ZGSmRkZBn2CAAAAGfD9AAAAABYHqEVAAAAllclpwdYSd36dcXuU9O09jOPZ5rWdqHqNczfjeo1rW9q+/u37Te1fRGR2rUdptdwOrNNr1Gzbi3Ta+zammx6jePHD5pe46KLSp4bX5bqN6lnavt//2X+PtWqc6DpNX5dus70Gl7VzB8HCuzU0vQaPtWrm17j8qHBpteY88JHprafn5tvavsiIjlZ5r/+duzYYFrbBQVl+xwx0goAAADLI7QCAADA8gitAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8gitAAAAsDxC6/83ceJEGTlypKe7AQAAgBIQWgEAAGB5FTa0njhxQrKyssqtXlpammRkZJRbPQAAAPyfChVa8/PzZenSpTJmzBjx8/OTXbt2yXfffSc2m03S0tKM2yUlJYnNZpOUlBQREYmLi5N69erJ119/LR07dpQ6derIlVdeKQcPnvk0juvXr5fGjRvL888/LyIiv//+uzRr1kxuuOEGWblypbhcLjMfKgAAAIqoEKF106ZN8uCDD4q/v7/cdNNN0rhxY1mzZo1069btnNs4deqUvPTSSzJv3jxZu3at7Nu3T6ZMmVLibVevXi2DBw+WZ555Rh5++GERERk4cKAsX75c7Ha7XHvttRIYGCjTpk2Tbdu2nVN9p9MpGRkZbhcAAACcG8uG1mPHjslrr70mPXv2lKCgINm9e7fMnj1bDh48KLNnz5bg4ODzai8vL0/efPNNCQoKkp49e0pkZKSsWrWq2O0WLVokI0aMkLfeeksmTZpkXG+z2SQkJETmzJkjhw4dkhdeeEF+++036dKli/Tt21fefPNNSU9PP2P92NhYcTgcxiUgIOC8+g8AAFCVWTa0zpw5U+677z6pU6eO7Ny5UxYtWiSjRo2SGjVqlKq9WrVqSdu2bY1/+/n5yd9//+12m19//VXGjBkj8+bNk+uuu+6MbdWsWVPGjRsny5cvl+TkZMnLy5PJkyfL+++/f8b7REdHS3p6unFJTU0t1eMAAACoiiwbWidNmiRPPfWUHDp0SDp37iw333yzrF69uthcUi+v0w9BVY3r8vLyirVXvXp1t3/bbDa3+4iItG3bVjp06CDvvfdeiW0Uys/Pl2XLlsm4ceOke/fu4nQ65YUXXpDx48ef8T52u118fX3dLgAAADg3lg2tzZs3l0ceeUS2b98uK1askBo1asioUaMkMDBQoqKiJDk5WUREGjduLCLidlBVUlJSqWo2atRIVq9eLTt37pSxY8cWC64bN26U+++/35hb26hRI1m7dq1s3rxZpk6davQFAAAAZcuyobWofv36yVtvvSWHDh2SF198UZKSkqRbt26yadMmadeunQQEBEhMTIzs2LFDli5dKi+//HKpazVp0kRWr14tW7dulXHjxkl+fr6IiHz//ffSt29fY27tgQMHZObMmRIUFFRWDxMAAABnUCFCayEfHx8JDw+XFStWyL59+yQwMFCqV68uCxYskK1bt8oll1wizz//vDz99NMXVKdZs2ayevVq2bRpk4wfP14KCgqkU6dO8tdff8mSJUsuaG4tAAAAzp+3pztQWs2bNzf+v3///vLHH3+4bS86X3XixIkyceJEt+0jR450u01cXJzbdj8/P7flrBo2bFgGvQYAAEBpVKiRVgAAAFRNhFYAAABYHqEVAAAAlkdoBQAAgOURWgEAAGB5FXb1gMqiWjVv8fY278+QczLHtLYL+TY0/+xef23/y9T2M49nmtq+iEh6+hHTa2RlnTC9hr2W3fQavS7/j+k10g6b/1xlHM0wvYbZ+67dXsvU9kVE8vMKTK9Rw1793290gU5mnDK9xonDaabXaF6/vuk11m/a9u83ukA5Wdmmtu90mv/3Tvs73fQa9eo1Ma3t/Pwzn120NBhpBQAAgOURWgEAAGB5hFYAAABYHqEVAAAAlkdoBQAAgOURWgEAAGB5hFYAAABYHqH1/5s4caKMHDnS090AAABACQitAAAAsLwKG1pPnDghWVlZ5VYvLS1NMjLMP7sNAAAAiqtQoTU/P1+WLl0qY8aMET8/P9m1a5d89913YrPZJC0tzbhdUlKS2Gw2SUlJERGRuLg4qVevnnz99dfSsWNHqVOnjlx55ZVy8ODBM9Zav369NG7cWJ5//nkREfn999+lWbNmcsMNN8jKlSvF5XKZ+VABAABQRIUIrZs2bZIHH3xQ/P395aabbpLGjRvLmjVrpFu3bufcxqlTp+Sll16SefPmydq1a2Xfvn0yZcqUEm+7evVqGTx4sDzzzDPy8MMPi4jIwIEDZfny5WK32+Xaa6+VwMBAmTZtmmzbdm7nT3Y6nZKRkeF2AQAAwLmxbGg9duyYvPbaa9KzZ08JCgqS3bt3y+zZs+XgwYMye/ZsCQ4OPq/28vLy5M0335SgoCDp2bOnREZGyqpVq4rdbtGiRTJixAh56623ZNKkScb1NptNQkJCZM6cOXLo0CF54YUX5LfffpMuXbpI37595c0335T09PQz1o+NjRWHw2FcAgICzqv/AAAAVZllQ+vMmTPlvvvukzp16sjOnTtl0aJFMmrUKKlRo0ap2qtVq5a0bdvW+Lefn5/8/fffbrf59ddfZcyYMTJv3jy57rrrzthWzZo1Zdy4cbJ8+XJJTk6WvLw8mTx5srz//vtnvE90dLSkp6cbl9TU1FI9DgAAgKrIsqF10qRJ8tRTT8mhQ4ekc+fOcvPNN8vq1auLzSX18jr9EFTVuC4vL69Ye9WrV3f7t81mc7uPiEjbtm2lQ4cO8t5775XYRqH8/HxZtmyZjBs3Trp37y5Op1NeeOEFGT9+/BnvY7fbxdfX1+0CAACAc2PZ0Nq8eXN55JFHZPv27bJixQqpUaOGjBo1SgIDAyUqKkqSk5NFRKRx48YiIm4HVSUlJZWqZqNGjWT16tWyc+dOGTt2bLHgunHjRrn//vuNubWNGjWStWvXyubNm2Xq1KlGXwAAAFC2LBtai+rXr5+89dZbcujQIXnxxRclKSlJunXrJps2bZJ27dpJQECAxMTEyI4dO2Tp0qXy8ssvl7pWkyZNZPXq1bJ161YZN26c5Ofni4jI999/L3379jXm1h44cEBmzpwpQUFBZfUwAQAAcAYVIrQW8vHxkfDwcFmxYoXs27dPAgMDpXr16rJgwQLZunWrXHLJJfL888/L008/fUF1mjVrJqtXr5ZNmzbJ+PHjpaCgQDp16iR//fWXLFmy5ILm1gIAAOD8eXu6A6XVvHlz4//79+8vf/zxh9v2ovNVJ06cKBMnTnTbPnLkSLfbxMXFuW338/NzW86qYcOGZdBrAAAAlEaFGmkFAABA1URoBQAAgOURWgEAAGB5hFYAAABYHqEVAAAAlldhVw+oLGr6+ohPzZqmtZ92+IRpbRfSAte/3+gCte7aytT2//zpT1PbFxE5fHiv+TUO7TG9xkUdupteo7ajtuk1fBuaf1a63Jwzn1mvrGxL3mhq+63bdjG1fRGR3kGdTa+xesFK02u0aNvS9BrHDx03vcaatYmm1+jXr7vpNbZ3aWVq+1vWbTa1fRGROvXrmF7DttdmXtu2sm2bkVYAAABYHqEVAAAAlkdoBQAAgOURWgEAAGB5hFYAAABYHqEVAAAAlkdoBQAAgOURWgEAAGB5nFyglBISEiQiIkJ8fHzcrne5XBISEiIzZ870UM8AAAAqH0JrKWVnZ0t4eLjExMS4XZ+SkiJRUVGe6RQAAEAlxfQAAAAAWB4jreXE6XSK0+k0/p2RkeHB3gAAAFQsjLSWk9jYWHE4HMYlICDA010CAACoMAit5SQ6OlrS09ONS2pqqqe7BAAAUGEwPaCc2O12sdvtnu4GAABAhcRIKwAAACyP0AoAAADLI7QCAADA8gitAAAAsDxCKwAAACyP1QNKyeFwSHx8vMTHxxfbFhYW5oEeAQAAVF6E1lIKDg6WxMRET3cDAACgSmB6AAAAACyP0AoAAADLY3qAhzUJaCI1a9c2rf1cZ55pbRdKP5pueo3ul3c3tf2Aji1NbV9E5JvlKabXOHLU/NMD52Y7Ta+hLjW9Rn6By/QaquY/jtTUraa236LFxaa2X15869czvYaXt/njQI38G5le4+iBY6bXqOtj/hki/Vo3M7X9FZ99Ymr7IiJBg3qbXmNzonk5oSC/bNtmpBUAAACWR2gFAACA5RFaAQAAYHmEVgAAAFgeoRUAAACWR2gFAACA5RFaAQAAYHmEVgAAAFhelTy5QEJCgkRERIiPj4/b9S6XS0JCQmTdunXidBZfQD0rK0uSk5NlxowZMm/ePPH2dn/6cnNzZfr06TJ+/HhT+w8AAFDVVMnQmp2dLeHh4RITE+N2fUpKikRFRYnNZpOkpKRi9wsNDRVVlRMnTsisWbMkNDTUbXtcXJxkZmaa13EAAIAqiukBAAAAsLwqOdLqCU6n023KQUZGhgd7AwAAULEw0lpOYmNjxeFwGJeAgABPdwkAAKDCILSWk+joaElPTzcuqampnu4SAABAhcH0gHJit9vFbrd7uhsAAAAVEiOtAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8gitAAAAsLwquXqAw+GQ+Ph4iY+PL7YtLCxM0tLSJCgoqMT7enl5ib+/v0yZMqXE7dOmTSvTvgIAAKCKhtbg4GBJTEws9f0jIyMlMjKyDHsEAACAs2F6AAAAACyP0AoAAADLq5LTA6zk4O6D4lOzlmnt22w209ouVL9ZA9NrZKZlmdr+od2HTG1fRKR9+96m16hXr4npNapVrxxvG7k5uabX+PvAX6bX6Ngx2NT2G7VoZGr7IiLpp06ZXmPPzi2m17jUb4DpNU6a/F4oItKhdwfTa2TmOE2vseXXraa237iRv6nti4ikbt1veo3adeqZ1nZ+ftm+zzLSCgAAAMsjtAIAAMDyCK0AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyCK0AAACwPEIrAAAALK9yrBLuAQkJCRIRESE+Pj5u17tcLgkJCZGZM2d6qGcAAACVD6G1lLKzsyU8PFxiYmLcrk9JSZGoqCjPdAoAAKCSIrSWE6fTKU7n/522LiMjw4O9AQAAqFiY01pOYmNjxeFwGJeAgABPdwkAAKDCILSWk+joaElPTzcuqampnu4SAABAhcH0gHJit9vFbrd7uhsAAAAVEiOtAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8gitAAAAsDxCKwAAACyPJa9KyeFwSHx8vMTHxxfbFhYW5oEeAQAAVF6E1lIKDg6WxMRET3cDAACgSmB6AAAAACyP0AoAAADLY3qAhzVt1VRq1q5tWvvN2/qZ1nahzOOZptfYtm6bqe03aN7A1PZFRA6u3mV6jTp16pleo2GLhqbXOPrXUdNr5GY7Ta+h6jK9xrFjf5navvf26qa2LyKyfUuK6TWuGH216TV2btxpeo2CggLTa7Rs28L0Glk5OabX8PIyd1zOz7+1qe2LiAR08De9xtZNv5nWdn5+Xpm2x0grAAAALI/QCgAAAMsjtAIAAMDyCK0AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyWKe1BAkJCRIRESE+Pj5u17tcLgkJCZF169aJ01l8jcesrCxJTk4Wu91eXl0FAACoEgitJcjOzpbw8HCJiYlxuz4lJUWioqLEZrNJUlJSsfuFhoaKqpZPJwEAAKoQpgcAAADA8hhpLSdOp9NtSkFGRoYHewMAAFCxMNJaTmJjY8XhcBiXgIAAT3cJAACgwiC0lpPo6GhJT083LqmpqZ7uEgAAQIXB9IByYrfbWVUAAACglBhpBQAAgOURWgEAAGB5hFYAAABYHqEVAAAAlkdoBQAAgOWxekAJHA6HxMfHS3x8fLFtYWFhkpaWJkFBQSXe18uL7wEAAABljdBaguDgYElMTPR0NwAAAPD/MSwIAAAAyyO0AgAAwPKYHuBhOVnZYnOZ993BVaCmtV0o43im6TXa92pvavvV7dVNbV9EpEYNH9Nr5OXlml4jOyPb9BonM7JMr3HqVLrpNcqD2fPoy2OfKsjLN73G3/v+Nr1GntP856plp0DTaxw+cNT0GqNCgk2v8V3LJqa2v3/XXlPbFxGp4dPZ9Bp2Ez+bqnlVK9P2GGkFAACA5RFaAQAAYHmEVgAAAFgeoRUAAACWR2gFAACA5RFaAQAAYHmEVgAAAFgeoRUAAACWVylPLpCQkCARERHi4+O+YK7L5ZKQkBBZt26dOJ3OYvfLysqS5ORkmTFjhsybN0+8vd2fntzcXJk+fbr07dtXhg4dKrVq1SrWRuvWrWXRokVl+4AAAACquEoZWrOzsyU8PFxiYmLcrk9JSZGoqCix2WySlJRU7H6hoaGiqnLixAmZNWuWhIaGum2Pi4uTzMxMycvLk379+klcXFyxNvr27Vt2DwQAAAAiwvQAAAAAVACVcqTVipxOp9uUhIyMDA/2BgAAoGJhpLWcxMbGisPhMC4BAQGe7hIAAECFQWgtJ9HR0ZKenm5cUlNTPd0lAACACoPpAeXEbreL3W73dDcAAAAqJEZaAQAAYHmEVgAAAFgeoRUAAACWR2gFAACA5RFaAQAAYHmVcvUAh8Mh8fHxEh8fX2xbWFiYpKWlSVBQUIn39fLyEn9/f5kyZUqJ26dNmyY1a9aUzZs3l9hG165dL6zzAAAAKKZShtbg4GBJTEws9f0jIyMlMjLyrLe5kPYBAABwfpgeAAAAAMsjtAIAAMDyKuX0gIrk2IFj4lMz27T2j/511LS2C9WtV8f0Gn5t/Extf9u6baa2LyJSo4aP6TVyck6aXsNey/wzu3l5VTO9RnZ2luk1/Pxam17j2NEDprbv5x9oavsiInm5+abXyM/NM72Go7HD9BptLjF/n6pdr7bpNTakpJheo26Duqa2v3+/+Z8be/80//XnVc28KOilWrbtlWlrAAAAgAkIrQAAALA8QisAAAAsj9AKAAAAyyO0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAy+PkAqWUkJAgERER4uPjvmC8y+WSkJAQmTlzpod6BgAAUPkQWkspOztbwsPDJSYmxu36lJQUiYqK8kynAAAAKimmBwAAAMDyGGktJ06nU5xOp/HvjIwMD/YGAACgYmGktZzExsaKw+EwLgEBAZ7uEgAAQIVBaC0n0dHRkp6eblxSU1M93SUAAIAKg+kB5cRut4vdbvd0NwAAACokRloBAABgeYRWAAAAWB6hFQAAAJZHaAUAAIDlEVoBAABgeaweUEoOh0Pi4+MlPj6+2LawsDAP9AgAAKDyIrSWUnBwsCQmJnq6GwAAAFUC0wMAAABgeYRWAAAAWB7TAzxs9++7pUYNH9Pav+jSi0xru1DSmt9Mr7Hha3OnYuTm5JravojIsHHhptdwZjtNr7H7992m1wjs1NL0Gl0adDG9xp4/zH+uRkdMMLX9PxI2mdq+iEh1n+qm18jNyTO9RsuO5u+3n74+z/QaTZoEmF7DVs38MTMtcJna/qV9LzO1fRGRk+knTa/h52/efpuXW7afSYy0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAyyO0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAy+PkAiVISEiQiIgI8fFxX/Tf5XJJSEiIrFu3TpzO4gvmZmVlSXJystjt9vLqKgAAQJVAaC1Bdna2hIeHS0xMjNv1KSkpEhUVJTabTZKSkordLzQ0VFS1fDoJAABQhTA9AAAAAJbHSGs5cTqdblMKMjIyPNgbAACAioWR1nISGxsrDofDuAQEBHi6SwAAABUGobWcREdHS3p6unFJTU31dJcAAAAqDKYHlBO73c6qAgAAAKXESCsAAAAsj9AKAAAAyyO0AgAAwPIIrQAAALA8QisAAAAsj9UDSuBwOCQ+Pl7i4+OLbQsLC5O0tDQJCgoq8b5eXnwPAAAAKGuE1hIEBwdLYmKip7sBAACA/49hQQAAAFgeoRUAAACWx/QAD7s0LEhq1qptWvs/f/mzaW0XatS8kek1+g7va2r7B3cfMrV9EZHP337P9Bp79vxheo1R191teo3tv201vcbff+81vcbFHXuaXuOzN83dr7p0Cza1fRGRatWqmV7jYKr5f+/MExmm15j46B2m1ziVccr0GpOvGWZ6jaf/N8/U9j954y1T2xcRGTlhouk11ixeZlrb+fl5ZdoeI60AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyCK0AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyquTJBRISEiQiIkJ8fHzcrne5XBISEiLr1q0Tp9NZ7H5ZWVmSnJwsM2bMkHnz5om3t/vTl5ubK9OnT5fx48eb2n8AAICqpkqG1uzsbAkPD5eYmBi361NSUiQqKkpsNpskJSUVu19oaKioqpw4cUJmzZoloaGhbtvj4uIkMzPTvI4DAABUUUwPAAAAgOVVyZFWT3A6nW5TDjIyzD9HNQAAQGXBSGs5iY2NFYfDYVwCAgI83SUAAIAKg9BaTqKjoyU9Pd24pKamerpLAAAAFQbTA8qJ3W4Xu93u6W4AAABUSIy0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAyyO0AgAAwPKq5OoBDodD4uPjJT4+vti2sLAwSUtLk6CgoBLv6+XlJf7+/jJlypQSt0+bNq1M+woAAIAqGlqDg4MlMTGx1PePjIyUyMjIMuwRAAAAzobpAQAAALA8QisAAAAsr0pOD7CSRk0bSK06dUxr32azmdZ2oYzjmabXUJea2n51e3VT2xcRycg4anqNkyfTTa/xV8oe02v0GtTf9BrHD7YyvcaGHxNMr5GZedzU9vft2WFq+yIi13UYbXqNtp07ml7jZFqW6TV+XvKz6TWG3DjI9BonnU7TaxxJPWJq+wUF+aa2LyLi29DX9BoFBXmmte1ylW3bjLQCAADA8gitAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8gitAAAAsDxCKwAAACyP0AoAAADLq5QnF0hISJCIiAjx8fFxu97lcklISIisW7dOnCUsbJyVlSXJyckyY8YMmTdvnnh7uz89ubm5Mn36dOnbt68MHTpUatWqVayN1q1by6JFi8r2AQEAAFRxlTK0ZmdnS3h4uMTExLhdn5KSIlFRUWKz2SQpKanY/UJDQ0VV5cSJEzJr1iwJDQ112x4XFyeZmZmSl5cn/fr1k7i4uGJt9O3bt+weCAAAAESkkoZWK3I6nW6juxkZGR7sDQAAQMXCnNZyEhsbKw6Hw7gEBAR4uksAAAAVBqG1nERHR0t6erpxSU1N9XSXAAAAKgymB5QTu90udrvd090AAACokBhpBQAAgOURWgEAAGB5hFYAAABYHqEVAAAAlkdoBQAAgOURWgEAAGB5lXLJK4fDIfHx8RIfH19sW1hYmKSlpUlQUFCJ9/Xy8hJ/f3+ZMmVKidunTZsmNWvWlM2bN5fYRteuXS+s8wAAACimUobW4OBgSUxMLPX9IyMjJTIy8qy3uZD2AQAAcH6YHgAAAADLI7QCAADA8irl9ICK5PBfR6VmrVOmte/lZTOt7UK+DeqaXiM/v8DU9nNO5pjavohIzZrmP0916zYwvUbgRe1Mr7H+2x9Nr5GVdcL0Gh26lDx3viz9tv47U9tv7t/G1PZFRA7sP2J6jZQtO0yv4esw//XXNeQS02v8/ddR02v49qlpeo2GzRua2r7D0djU9kVETqafNL1GjRo+prWdn1+tTNtjpBUAAACWR2gFAACA5RFaAQAAYHmEVgAAAFgeoRUAAACWR2gFAACA5RFaAQAAYHmEVgAAAFhelTy5QEJCgkRERIiPj/uCui6XS0JCQmTdunXidDqL3S8rK0uSk5NlxowZMm/ePPH2dn/6cnNzZfr06TJ+/HhT+w8AAFDVVMnQmp2dLeHh4RITE+N2fUpKikRFRYnNZpOkpKRi9wsNDRVVlRMnTsisWbMkNDTUbXtcXJxkZmaa13EAAIAqqkqGVk9wOp1uo7cZGRke7A0AAEDFwpzWchIbGysOh8O4BAQEeLpLAAAAFQahtZxER0dLenq6cUlNTfV0lwAAACoMpgeUE7vdLna73dPdAAAAqJAYaQUAAIDlEVoBAABgeYRWAAAAWB6hFQAAAJZHaAUAAIDlEVoBAABgeVVyySuHwyHx8fESHx9fbFtYWJikpaVJUFBQiff18vISf39/mTJlSonbp02bVqZ9BQAAQBUNrcHBwZKYmFjq+0dGRkpkZGQZ9ggAAABnw/QAAAAAWB6hFQAAAJZXJacHWEnWiUzJzykwrf1mbfxMa7vQ1l+3ml4jPzff1PZTt+wztX0Rkc6d+5lew8enluk1stJOml6jTacOptfIOpFleo3UPTtMr9Hlkv6mtp+bk2tq+yIiWenm/y28qpn/cVfLUdv0Gt41zH8crgLzPpMKzf/+B9Nr7Pptp6nt16pZ19T2RUS2rjP/87VRI3/T2s7Lc5Zpe4y0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAyyO0AgAAwPIIrQAAALA8QisAAAAsr1Ku05qQkCARERHi4+Pjdr3L5ZKQkBBZt26dOJ3F1w7LysqS5ORkmTFjhsybN0+8vd2fntzcXJk+fbr07dtXhg4dKrVqFV8Ts3Xr1rJo0aKyfUAAAABVXKUMrdnZ2RIeHi4xMTFu16ekpEhUVJTYbDZJSkoqdr/Q0FBRVTlx4oTMmjVLQkND3bbHxcVJZmam5OXlSb9+/SQuLq5YG3379i27BwIAAAARYXoAAAAAKoBKOdJqRU6n021KQkZGhgd7AwAAULEw0lpOYmNjxeFwGJeAgABPdwkAAKDCILSWk+joaElPTzcuqampnu4SAABAhcH0gHJit9vFbrd7uhsAAAAVEiOtAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8gitAAAAsLxKuXqAw+GQ+Ph4iY+PL7YtLCxM0tLSJCgoqMT7enl5ib+/v0yZMqXE7dOmTZOaNWvK5s2bS2yja9euF9Z5AAAAFFMpQ2twcLAkJiaW+v6RkZESGRl51ttcSPsAAAA4P0wPAAAAgOURWgEAAGB5lXJ6QEWSfjRdcnxyTWt/V9Iu09ouVKd+HdNr2Gzmtt84oLG5BURk/U+rTa9RHuo2qGt6jSOpR0yvcfJkmuk1eg7sZ3qNlYs+N7X9S3r8x9T2RUTyc/NNr+HfNtD0Gt7Vq5lew3nKaXoNb+/KEQ16XNHD1Pb/fHWdqe2LiFwS3Nv0Gls2/G5a2/n5ZZtvGGkFAACA5RFaAQAAYHmEVgAAAFgeoRUAAACWR2gFAACA5RFaAQAAYHmEVgAAAFgeoRUAAACWVzlWEPaAhIQEiYiIEB8fH7frXS6XhISEyMyZMz3UMwAAgMqH0FpK2dnZEh4eLjExMW7Xp6SkSFRUlGc6BQAAUEkxPQAAAACWx0hrOXE6neJ0/t85ozMyMjzYGwAAgIqFkdZyEhsbKw6Hw7gEBAR4uksAAAAVBqG1nERHR0t6erpxSU1N9XSXAAAAKgymB5QTu90udrvd090AAACokBhpBQAAgOURWgEAAGB5hFYAAABYHqEVAAAAlkdoBQAAgOWxekApORwOiY+Pl/j4+GLbwsLCPNAjAACAyovQWkrBwcGSmJjo6W4AAABUCUwPAAAAgOURWgEAAGB5TA/wsKDLekitOnVMa/+P738zre1Cbbu3Nb2G2U78nWZ6DafzlOk10tOPmF7Dq5r533WbBjY1vcbR/eY/jt9/XG96DZvN3MdRs46Pqe2LiLTv1s70GonLzf9b1K5n3nt5oeMHj5teo3nb5qbX6Nmmtek1Xv5otante1WrZmr7IiLZWdmm10hLM+9zo6Agr0zbY6QVAAAAlkdoBQAAgOURWgEAAGB5hFYAAABYHqEVAAAAlkdoBQAAgOURWgEAAGB5hFYAAABYXpU8uUBCQoJERESIj4/7otkul0tCQkJk3bp14nQ6i90vKytLkpOTZcaMGTJv3jzx9nZ/+nJzc2X69Okyfvx4U/sPAABQ1VTJ0JqdnS3h4eESExPjdn1KSopERUWJzWaTpKSkYvcLDQ0VVZUTJ07IrFmzJDQ01G17XFycZGZmmtdxAACAKorpAQAAALC8KjnS6glOp9NtykFGRoYHewMAAFCxMNJaTmJjY8XhcBiXgIAAT3cJAACgwiC0lpPo6GhJT083LqmpqZ7uEgAAQIXB9IByYrfbxW63e7obAAAAFRIjrQAAALA8QisAAAAsj9AKAAAAyyO0AgAAwPIIrQAAALC8Krl6gMPhkPj4eImPjy+2LSwsTNLS0iQoKKjE+3p5eYm/v79MmTKlxO3Tpk0r074CAACgiobW4OBgSUxMLPX9IyMjJTIysgx7BAAAgLNhegAAAAAsj9AKAAAAy7Opqnq6E1VRRkaGOBwOuX5ClNSo4WNanYAO/qa1XSj5xz9Nr1GvicPU9p3Zuaa2LyLSOKCx6TUK8gpMr5G6zfxTELfq0sr0GvWa1DO9xp4/9phew7+9ua/xrb9sMbV9EZG+w/uaXmPLr1tNr1Ee+9RPK1aaXqNTj5KP6ShLOSdzyqGG09T2G/g1MLV9kXJ6nk6ZVyMvzylLFs2U9PR08fX1veD2GGkFAACA5RFaAQAAYHmEVgAAAFgeoRUAAACWR2gFAACA5RFaAQAAYHmEVgAAAFgeoRUAAACW5+3pDlhRQkKCREREiI+P+6L/LpdLQkJCZN26deJ0Fl+0OCsrS5KTk8Vut5dXVwEAAKoEQmsJsrOzJTw8XGJiYtyuT0lJkaioKLHZbJKUlFTsfqGhocIJxgAAAMoe0wMAAABgeYy0lhOn0+k2pSAjI8ODvQEAAKhYGGktJ7GxseJwOIxLQECAp7sEAABQYRBay0l0dLSkp6cbl9TUVE93CQAAoMJgekA5sdvtrCoAAABQSoy0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAyyO0AgAAwPJYPaAEDodD4uPjJT4+vti2sLAwSUtLk6CgoBLv6+XF9wAAAICyRmgtQXBwsCQmJnq6GwAAAPj/GBYEAACA5RFaAQAAYHlMD/CwOvXqSA27j2ntH91/1LS2C9XwqWF6jXpN65vavs1mM7V9EZEdG7ebXuP48YOm16hbt4HpNRyNHabXsNc0/wx1vg19Ta+xY8MOU9vPyTllavsiIi0u9je9xsZvfzO9hk9t897LC7nUZXqNBn4NTa/RpGUT02ts/mGzqe0fTNlvavsiIt1DLzW9xteffGFa2wUFeWXaHiOtAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8gitAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8qrkyQUSEhIkIiJCfHzcF4J2uVwSEhIi69atE6fTWex+WVlZkpycLDNmzJB58+aJt7f705ebmyvTp0+X8ePHm9p/AACAqqZKhtbs7GwJDw+XmJgYt+tTUlIkKipKbDabJCUlFbtfaGioqKqcOHFCZs2aJaGhoW7b4+LiJDMz07yOAwAAVFFVMrR6gtPpdBu9zcjI8GBvAAAAKhbmtJaT2NhYcTgcxiUgIMDTXQIAAKgwCK3lJDo6WtLT041Lamqqp7sEAABQYTA9oJzY7Xax2+2e7gYAAECFxEgrAAAALI/QCgAAAMsjtAIAAMDyCK0AAACwPEIrAAAALI/QCgAAAMurkkteORwOiY+Pl/j4+GLbwsLCJC0tTYKCgkq8r5eXl/j7+8uUKVNK3D5t2rQy7SsAAACqaGgNDg6WxMTEUt8/MjJSIiMjy7BHAAAAOBumBwAAAMDyCK0AAACwvCo5PcBK6tSvI3afmqa1n3Myx7S2CzWrZf7paU+mnTS1/S4DOpvavojIWy89ZnqNtm27m16jfr2mptfIPJ5peg0tcJleY9j1g0yvMXHICFPbb9eup6nti4gc3X/E9Bqtu7Y2vcZv35V+2tm5atCguek1WnYMML2GTx3zPvcKtenWxtT2N/yy2tT2RUSuvtjc17eISGrqFtPadrnK9n2WkVYAAABYHqEVAAAAlkdoBQAAgOURWgEAAGB5hFYAAABYHqEVAAAAlkdoBQAAgOURWgEAAGB5hNYL8N1334nNZpOUlBSJiYmRVq1aebpLAAAAlRKh9QKkpKRIu3btpEWLFrJnzx4JDQ31dJcAAAAqJU7jegFWrFghzz77rHh7e8t3330nP/zwwxlv63Q6xel0Gv/OyMgojy4CAABUCoTWC/Dxxx8b/793796z3jY2NlaeeOIJs7sEAABQKTE9oJxER0dLenq6cUlNTfV0lwAAACoMRlrLid1uF7vd7uluAAAAVEiMtAIAAMDyCK0AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyCK0AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyCK0AAACwPE7j6mG169UWn5q1TGt/x8YdprVdqEPvDqbX8PKuZmr7Kcl7TW1fRKRBAz/Ta+Tm5pheo259X9NrpP2dZnqN4weOm17j2EHza9Sr18TU9h2Oxqa2LyLSvJX5r43NPySbXqOuo57pNfJz802v0btnJ9Nr+FSvYXqNWUvXmdp+o4YtTG1fRORI6hHTa1Sv7mNa2y5XQZm2x0grAAAALI/QCgAAAMsjtAIAAMDyCK0AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyKuU6rQkJCRIRESE+Pu5rj7lcLgkJCZF169aJ0+ksdr+srCxJTk6WGTNmyLx588Tb2/3pyc3NlenTp0vfvn1l6NChUqtW8fVVW7duLYsWLSrbBwQAAFDFVcrQmp2dLeHh4RITE+N2fUpKikRFRYnNZpOkpKRi9wsNDRVVlRMnTsisWbMkNDTUbXtcXJxkZmZKXl6e9OvXT+Li4oq10bdv37J7IAAAABARpgcAAACgAqiUI61W5HQ63aYkZGRkeLA3AAAAFQsjreUkNjZWHA6HcQkICPB0lwAAACoMQms5iY6OlvT0dOOSmprq6S4BAABUGEwPKCd2u13sdrunuwEAAFAhMdIKAAAAyyO0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAy6uUqwc4HA6Jj4+X+Pj4YtvCwsIkLS1NgoKCSryvl5eX+Pv7y5QpU0rcPm3aNKlZs6Zs3ry5xDa6du16YZ0HAABAMZUytAYHB0tiYmKp7x8ZGSmRkZFnvc2FtA8AAIDzw/QAAAAAWB6hFQAAAJZXKacH4P80btHI9BrHDx03vcap9FOmtt9lYBdT2xcRUVXTazh8zf97F+S7zK+RV2B6jer26qbX6NCng+k1Vi4xd7/KyTlpavsiIqk7/zK9RouLWphe4/DeQ6bXyM3NMb3G8qU/mF7Dr7Wf6TV8G/ma2n5d3wamti8i0jigsek1fH0bmtZ2QUF+mbbHSCsAAAAsj9AKAAAAyyO0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAyyO0AgAAwPIIrQAAALA8Ti5QgoSEBImIiBAfHx+3610ul4SEhMi6devE6XQWu19WVpYkJyeL3W4vr64CAABUCYTWEmRnZ0t4eLjExMS4XZ+SkiJRUVFis9kkKSmp2P1CQ0PL5axHAAAAVQ3TAwAAAGB5jLSWE6fT6TalICMjw4O9AQAAqFgYaS0nsbGx4nA4jEtAQICnuwQAAFBhEFrLSXR0tKSnpxuX1NRUT3cJAACgwmB6QDmx2+2sKgAAAFBKjLQCAADA8gitAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8lg9oAQOh0Pi4+MlPj6+2LawsDBJS0uToKCgEu/r5cX3AAAAgLJGaC1BcHCwJCYmerobAAAA+P8YFgQAAIDlEVoBAABgeUwP8DDnyRyRAptp7efl5pvWdiG/Ns1Mr2Gvae7ZxDYlbDK1fRGRSy4JMb2Gj08t02vUqV/H9Bp7t+8wvUZ2dpbpNVJ37jG9Rq++g01tPzMt09T2RUSatW5qeo3kH5NNr9G8TXPTa+xK3m56jdZdWpleo3GDeqbXWPtZgqnt16pT19T2RUT++O5302t4e1c3rW2brWzzDSOtAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8gitAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8ji5QCklJCRIRESE+Pj4uF3vcrkkJCREZs6c6aGeAQAAVD6E1lLKzs6W8PBwiYmJcbs+JSVFoqKiPNMpAACASorpAQAAALA8RlrLidPpFKfTafw7IyPDg70BAACoWBhpLSexsbHicDiMS0BAgKe7BAAAUGEQWstJdHS0pKenG5fU1FRPdwkAAKDCYHpAObHb7WK32z3dDQAAgAqJkVYAAABYHqEVAAAAlkdoBQAAgOURWgEAAGB5hFYAAABYHqsHlJLD4ZD4+HiJj48vti0sLMwDPQIAAKi8CK2lFBwcLImJiZ7uBgAAQJXA9AAAAABYHqEVAAAAlsf0AA9r2KKR1KxVy7T2D+w6aFrbhbat3256jfAHx5ja/m9rfze1fRGR9T99a3qNffv+NL1Gv+CRpteoV6+x6TUaN2theg1Xgcv0Gn/89qOp7TdtGmhq+yIijprmvQcWOrDH/FNnNws0f59q3fEi02vsStpleo2ht11reo11QReb2v53C1eY2r6IyCUhXU2vUetnh2lt5+fnlWl7jLQCAADA8gitAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8gitAAAAsDxCKwAAACyP0AoAAADLq5QnF0hISJCIiAjx8fFxu97lcklISIisW7dOnE5nsftlZWVJcnKyzJgxQ+bNmyfe3u5PT25urkyfPl369u0rQ4cOlVolnBSgdevWsmjRorJ9QAAAAFVcpQyt2dnZEh4eLjExMW7Xp6SkSFRUlNhsNklKSip2v9DQUFFVOXHihMyaNUtCQ0PdtsfFxUlmZqbk5eVJv379JC4urlgbffv2LbsHAgAAABFhegAAAAAqgEo50mpFTqfTbUpCRkaGB3sDAABQsTDSWk5iY2PF4XAYl4CAAE93CQAAoMIgtJaT6OhoSU9PNy6pqame7hIAAECFwfSAcmK328Vut3u6GwAAABUSI60AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyCK0AAACwvEq5eoDD4ZD4+HiJj48vti0sLEzS0tIkKCioxPt6eXmJv7+/TJkypcTt06ZNk5o1a8rmzZtLbKNr164X1nkAAAAUUylDa3BwsCQmJpb6/pGRkRIZGXnW21xI+wAAADg/TA8AAACA5RFaAQAAYHk2VVVPd6IqysjIEIfDIREPPCt2u49pdY4fPG5a24Xa9Wxneo3t67eZ2n5Wepap7YuI1HHUMb2Gq8D8l3O9Jg7TazRs0cj0Gs5TTtNr7Pljt+k1mrXxM7V9l8tlavsiIv4X+5teY1fSLtNr5Gbnml7j7wMHTK8xfNI1ptfYts7c93QRkb92/GVq+15eNlPbFxGx2cyvceqUeZ9/eXm5snLl+5Keni6+vr4X3B4jrQAAALA8QisAAAAsj9AKAAAAyyO0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAyyO0AgAAwPK8Pd2BiiohIUEiIiLEx8f9xAAul0tCQkJk5syZHuoZAABA5UNoLaXs7GwJDw+XmJgYt+tTUlIkKirKM50CAACopJgeAAAAAMtjpLWcOJ1OcTr/71znGRkZHuwNAABAxcJIazmJjY0Vh8NhXAICAjzdJQAAgAqD0FpOoqOjJT093bikpqZ6uksAAAAVBtMDyondbhe73e7pbgAAAFRIjLQCAADA8gitAAAAsDxCKwAAACyP0AoAAADLI7QCAADA8lg9oJQcDofEx8dLfHx8sW1hYWEe6BEAAEDlRWgtpeDgYElMTPR0NwAAAKoEpgcAAADA8gitAAAAsDymB3hY5rEMcdbINa39JoFNTGu70Pb120yvUbeBr6nte9eobmr7IiLV7ebXaBrY1PQaB3YeML3Gnz/9aXoNLy+b6TX82/ubXiPXmWdq+6fST5nafnmpU6+O6TWqNzX/NZ6bY97nRaHkHzabXqM81PCpYWr7tR21TG1fRMR5yml6jYz046a1XZBftvsrI60AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyCK0AAACwPEIrAAAALI/QCgAAAMsjtAIAAMDyquTJBRISEiQiIkJ8fHzcrne5XBISEiLr1q0Tp7P4gr5ZWVmSnJwsM2bMkHnz5om3t/vTl5ubK9OnT5fx48eb2n8AAICqpkqG1uzsbAkPD5eYmBi361NSUiQqKkpsNpskJSUVu19oaKioqpw4cUJmzZoloaGhbtvj4uIkMzPTvI4DAABUUVUytHqC0+l0G73NyMjwYG8AAAAqFua0lpPY2FhxOBzGJSAgwNNdAgAAqDAIreUkOjpa0tPTjUtqaqqnuwQAAFBhMD2gnNjtdrHb7Z7uBgAAQIXESCsAAAAsj9AKAAAAyyO0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAy6uSS145HA6Jj4+X+Pj4YtvCwsIkLS1NgoKCSryvl5eX+Pv7y5QpU0rcPm3atDLtKwAAAKpoaA0ODpbExMRS3z8yMlIiIyPLsEcAAAA4G6YHAAAAwPIIrQAAALC8Kjk9wEq6hXYTn1q1TGt/0RufmNZ2oX5DQ02v0ax1U1PbzziWYWr7IiIzYx41vYaqml6jb9//ml6jZYdA02scSjlkeo0Th9NMr7H8yzhT2x91/WRT2xcRada6mek11i9fb3qNmnVqml6j15UlH29Rllp3amV6jX4XXWR6jedffN/U9j+Lm21q+yIik6IeMb3GupnfmNZ2QUFBmbbHSCsAAAAsj9AKAAAAyyO0AgAAwPIIrQAAALA8QisAAAAsj9AKAAAAyyO0AgAAwPKq5DqtCQkJEhERIT4+Pm7Xu1wuCQkJkXXr1onT6Sx2v6ysLElOTpYZM2bIvHnzxNvb/enLzc2V6dOny/jx403tPwAAQFVTJUNrdna2hIeHS0xMjNv1KSkpEhUVJTabTZKSkordLzQ0VFRVTpw4IbNmzZLQ0FC37XFxcZKZmWlexwEAAKoopgcAAADA8qrkSKsnOJ1OtykHGRnmnzYUAACgsmCktZzExsaKw+EwLgEBAZ7uEgAAQIVBaC0n0dHRkp6eblxSU1M93SUAAIAKg+kB5cRut4vdbvd0NwAAACokRloBAABgeYRWAAAAWB6hFQAAAJZHaAUAAIDlEVoBAABgeVVy9QCHwyHx8fESHx9fbFtYWJikpaVJUFBQiff18vISf39/mTJlSonbp02bVqZ9BQAAQBUNrcHBwZKYmFjq+0dGRkpkZGQZ9ggAAABnw/QAAAAAWB6hFQAAAJZXJacHWElWWub/a+/eY6I68zCOP+BlpjrMGLY0goyQjcCitVJbu0VJbMQsprurXRrtNI29pPHyR0MbbeOQNMH2j6VWa2pJ2DQ1vRlixtY0MdAaY9YLy8ZsyC5KuiqIUIeC6fayDLYwXIb9wzgtcd266DvzzvD9JCeRufye9xyZyePxwGgkPGps/py5ucZmX9Pd1m08Y3TU3DGSpLmFc43Ol6SI4X2QpDGNGc8YHPzeeEbmL2cbz8guyDaeMTI0bDzjSIPZt/GWU01G50vSvaX3Gs8ofLDQeMaX7V8azzj4p33GMzb/cYvxjIZTE79EzxZz5y4wnpGdb/59yuPJMDZ7dPT2vgdyphUAAADWo7QCAADAepRWAAAAWI/SCgAAAOtRWgEAAGA9SisAAACsR2kFAACA9SitAAAAsB4fLjBBJ06c0KZNm+R0OsfdHolEtHz5ctXU1MRpZQAAAMmH0jpBAwMD8vl82r59+7jbu7q65Pf747MoAACAJMXlAQAAALAeZ1pjJBwOKxwOR78OhUJxXA0AAEBi4UxrjFRXV8vj8UQ3r9cb7yUBAAAkDEprjFRWVqqvry+6BYPBeC8JAAAgYXB5QIw4HA45HI54LwMAACAhcaYVAAAA1qO0AgAAwHqUVgAAAFiP0goAAADrUVoBAABgPX57wAR5PB7V19ervr7+uvvKysrisCIAAIDkRWmdoOLiYjU3N8d7GQAAAJMClwcAAADAepRWAAAAWI/LA+LszMlWTZtm7pOy3OlpxmZfk7Mg13iGc6bT6PzLF3uNzpek/IIlxjO8OfnGM3q/7DKeMdPjMp6ROiXFeEbuvDzjGUVFpUbnO50zjc6XpPBA2HhGb4f513jf1/82njGvcJHxjL8f/YfxjGmOacYzpkwzW3HOnv2r0fmSdP5vvzGecebMMWOzx8bGbus8zrQCAADAepRWAAAAWI/SCgAAAOtRWgEAAGA9SisAAACsR2kFAACA9SitAAAAsB6lFQAAANajtAIAAMB6CV9av/vuO125ciUmWZcuXYpJDgAAAMZLyNI6MjKihoYGrV27VpmZmero6JAkBYNBrVu3TrNmzVJ6errWrFmjrq6u6PMikYheffVVZWdny+FwqKioSIcPH47ePzQ0pOeee06ZmZlyOp3KyclRdXV19P6nnnpKd999t3bu3KneXvMfCQgAAICrEqq0tra2auvWrcrOztaTTz6pjIwMHTt2TIsWLdLw8LDKysqUlpamxsZGNTU1yeVyadWqVRoaGpIk7dmzR2+88YZ27dqlM2fOqKysTKtXr1Z7e7sk6a233tKhQ4d04MABnT9/XnV1dcrNzY3mHzhwQBs3blQgEJDX69XDDz+sQCCgwcHBn117OBxWKBQatwEAAODmWF9av/nmG+3Zs0eLFy/W/fffr4sXL6q2tla9vb2qra1VcXGxJCkQCCgSiWjv3r1auHChCgsL9d577+nSpUs6fvy4JGnXrl3atm2bfD6fCgoKtGPHDhUVFenNN9+UdPW///Py8lRSUqKcnByVlJTo8ccfj64lIyNDFRUVam5uVmtrq+655x69+OKLyszM1ObNm3Xq1Kkb7kd1dbU8Hk9083q9xo4ZAABAsrG+tNbU1OiFF16Qy+XShQsX9Mknn6i8vFzTp08f97jTp0/rwoULSktLk8vlksvlUnp6ugYHB9XR0aFQKKSenh4tW7Zs3POWLVums2fPSpKefvpptbS0qKCgQBUVFTpy5MgN11VYWKjXXntNX3zxhfx+v959912tWrXqho+vrKxUX19fdAsGg7dwVAAAACaXqfFewM/ZuHGjpk6dqg8//FALFizQo48+qvXr1+uhhx5SauqPnfvKlSu67777VFdXd92MjIyMm8pavHixOjs79dlnn+no0aNat26dVq5cqY8//vi6xwaDQdXV1Wnfvn3q7OzU2rVr9cwzz9xwtsPhkMPhuKl1AAAAYDzrz7RmZWXp5ZdfVltbmw4fPqzp06ervLxcOTk58vv9+vzzzyVdLZzt7e266667NG/evHGbx+OR2+1WVlaWmpqaxs1vamrS/Pnzo1+73W499thjeueddxQIBHTw4EF9++23kqT+/n69//77WrFihXJzc9XQ0KAtW7bo8uXLqqur08qVK2N3YAAAACYR60vrTy1dulRvv/22Ll++rJ07d6qlpUWLFi1Sa2urnnjiCd15551as2aNGhsb1dnZqePHj6uiokLd3d2SpJdeekk7duxQIBDQ+fPn5ff71dLSoueff16StHv3bu3fv1/nzp1TW1ubPvroI82ePVuzZs2SJD3yyCN65ZVXVFJSora2NjU2NurZZ5+V2+2O1yEBAACYFKy/POC/cTqd8vl88vl86unpkcvl0owZM3Ty5Elt27ZN5eXl6u/v15w5c1RaWhotlRUVFerr69PWrVv11Vdfaf78+Tp06JDy8vIkSWlpaXr99dfV3t6uKVOmaMmSJfr000+jlyHU1tYqPz9fKSkpcdt3AACAySghS+tPZWVlRf88e/ZsffDBBzd8bGpqqqqqqlRVVfVf79+wYYM2bNhww+cXFBRMfKEAAACYsIS6PAAAAACTE6UVAAAA1qO0AgAAwHqUVgAAAFiP0goAAADrJfxvD0h0S1cvlXPGDGPz9+/ea2z2Ndn52cYz3L8w+7twg+fMf6xuZ+cZ4xnh8IDxjAdXlBrP+MvBRuMZXV3/NJ5R+offG884ffrPRueX/W690fmSlJ6ZbjzjDvcd5jNcWT//oFv0wG9/bTxjaCBsPOOBhb8ynrF/X4PR+TNneozOl6Svu/9lPCMjw2tsdiQyqt7ei7dtHmdaAQAAYD1KKwAAAKxHaQUAAID1KK0AAACwHqUVAAAA1qO0AgAAwHqUVgAAAFiP0goAAADr8eECE3TixAlt2rRJTqdz3O2RSETLly9XTU1NnFYGAACQfCitEzQwMCCfz6ft27ePu72rq0t+vz8+iwIAAEhSXB4AAAAA63GmNUbC4bDC4R8/zzkUCsVxNQAAAImFM60xUl1dLY/HE928Xm+8lwQAAJAwKK0xUllZqb6+vugWDAbjvSQAAICEweUBMeJwOORwOOK9DAAAgITEmVYAAABYj9IKAAAA61FaAQAAYD1KKwAAAKxHaQUAAID1+O0BE+TxeFRfX6/6+vrr7isrK4vDigAAAJIXpXWCiouL1dzcHO9lAAAATApcHgAAAADrcaY1TsbGxiRJgwM/GM0ZGRk2Ol+SwoMDxjMGfvje6Pyh8KDR+ZIUiUSMZ4yOmv/7jsWxGh4OG8+IxbGKxWvD9PfV0JD5v++B782+vqXYfN8qMmY8IibHatD86+9Kf7/xDNOvv1i8p8fi9ReJjBqcffUYXes8typl7HZNwv+lu7tbXq833ssAAAAwKhgMKjs7+5bnUFrjJBKJqKenR2lpaUpJSbmp54RCIXm9XgWDQbnd7tu+JtPzyZh8GcmwD2TYlZEM+0CGXRnJsA+2ZoyNjam/v19ZWVlKTb31K1K5PCBOUlNTJ/yvDrfbbewbMhbzyZh8GcmwD2TYlZEM+0CGXRnJsA82Zng8ntuWyw9iAQAAwHqUVgAAAFiP0ppAHA6Hqqqq5HA4EnI+GZMvIxn2gQy7MpJhH8iwKyMZ9iGZMv4XfhALAAAA1uNMKwAAAKxHaQUAAID1KK0AAACwHqUVAAAA1qO0AgAAwHqUVgAAAFiP0goAAADrUVoBAABgvf8AZIPaDZnxzoQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(src_tokens, trg_tokens, attention)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "714d3f4db9a58ba7d2f2a9a4fffe577af3df8551aebd380095064812e2e0a6a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
