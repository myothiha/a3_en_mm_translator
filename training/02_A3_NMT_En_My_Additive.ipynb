{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW2Le2rdK6Zd"
      },
      "source": [
        "# Machine Translation + Transformer\n",
        "\n",
        "<img src = \"../figures/transformer1.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g05u7tTDOQxf",
        "outputId": "fc926da0-aa20-40f4-f843-41f14acb9013"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f2B3PFbNNAd",
        "outputId": "29768f3b-0ae5-4fad-9e7f-2764537dbd65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘models/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ8u6WwRK6Zh",
        "outputId": "86312eb4-638e-45f2-b0f0-2a6e40efc2d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyidaungsu in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyidaungsu) (1.23.5)\n",
            "Requirement already satisfied: python-crfsuite in /usr/local/lib/python3.10/dist-packages (from pyidaungsu) (0.9.10)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from pyidaungsu) (2.10.1)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from pyidaungsu) (2.11.1)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (from pyidaungsu) (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext->pyidaungsu) (67.7.2)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata) (1.3.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.23.5)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchtext) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.8.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyidaungsu\n",
        "!pip3 install torchdata\n",
        "!pip3 install torchtext\n",
        "!pip3 install portalocker\n",
        "!pip3 install datasets\n",
        "!pip3 install spacy\n",
        "!python3 -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW0fqtIgK6Zj",
        "outputId": "4b9b5889-ad7c-490e-c8ab-be93448ab470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch, torchdata, torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pyidaungsu as pds\n",
        "\n",
        "import random, math, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-u6vONbIK6Zj"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3o_5lt3dK6Zk",
        "outputId": "61bcf5ac-1ead-4d34-b6b8-cf3a9c03d91d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dT2lraVxK6Zk",
        "outputId": "a978c751-630f-4877-eb3d-43c973898492"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.16.0+cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "v_c3EBN7K6Zk"
      },
      "source": [
        "## 1. ETL: Loading the dataset\n",
        "\n",
        "**Note**: Here I chose to translate English to German, simply it is easier for myself, since I don't understand German so it is difficult for me to imagine a sentence during inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJYqEm7-K6Zl",
        "outputId": "ea17740e-ef82-4e4d-b506-b68b48321a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torchtext, datasets\n",
        "\n",
        "SRC_LANGUAGE = 'en'\n",
        "TRG_LANGUAGE = 'my'\n",
        "\n",
        "# train = Multi30k(split=('train'), language_pair=(SRC_LANGUAGE, TRG_LANGUAGE))\n",
        "dataset = datasets.load_dataset('myothiha/mm_eng_alt_corpus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlUB_lxuK6Zl",
        "outputId": "19f2a400-7bdd-4902-df1f-2bc26b813f3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "type(dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "75K3-3EdK6Zl"
      },
      "outputs": [],
      "source": [
        "train = [(row['en'], row['my']) for row in dataset['train']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU_Ouha8K6Zm",
        "outputId": "e35c68ca-95a9-48f4-8ce5-603fb6890ef5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
              " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Z_dC0d7-K6Zm"
      },
      "source": [
        "## 2. EDA - simple investigation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUsY3lUnK6Zm",
        "outputId": "bb930249-e451-42a0-f799-17d6bcbe30e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
              " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#let's take a look at one example of train\n",
        "sample = train[0]\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnfX8Pj5K6Zn",
        "outputId": "f78df017-ac83-42db-fe9f-6c8e2cf19302"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16280"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_size = len(train)\n",
        "train_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlBPa57KK6Zn"
      },
      "source": [
        "Since 29001 is plenty,, we gonna call `random_split` to train, val and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mjZ9kynUK6Zn"
      },
      "outputs": [],
      "source": [
        "# train, val, test = train.random_split(total_length=train_size, weights = {\"train\": 0.7, \"val\": 0.2, \"test\": 0.1}, seed=999)\n",
        "val = [(row['en'], row['my']) for row in dataset['validation']]\n",
        "test = [(row['en'], row['my']) for row in dataset['test']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrwX_G-jK6Zn",
        "outputId": "f30f2937-9c9b-4f0d-bfca-5daa14719fee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16280"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_size = len(train)\n",
        "train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVsyuDedK6Zo",
        "outputId": "5a860d3f-1b79-444f-9618-c5947ac0cf1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1809"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "val_size = len(val)\n",
        "val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv7qDMjpK6Zo",
        "outputId": "c095dae6-a215-474f-8a57-6470c531fc1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2010"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "test_size = len(test)\n",
        "test_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "XOLSghmbK6Zo"
      },
      "source": [
        "## 3. Preprocessing\n",
        "\n",
        "### Tokenizing\n",
        "\n",
        "**Note**: the models must first be downloaded using the following on the command line:\n",
        "```\n",
        "python3 -m spacy download en_core_web_sm\n",
        "python3 -m spacy download de_core_news_sm\n",
        "```\n",
        "\n",
        "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dSzV7tBYK6Zp"
      },
      "outputs": [],
      "source": [
        "# !python3 -m spacy download en_core_web_sm\n",
        "# !python3 -m spacy download de_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "T2no_bINK6Zp"
      },
      "outputs": [],
      "source": [
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TNk_Io-HK6Zp"
      },
      "outputs": [],
      "source": [
        "# Myanmar word tokenizer.\n",
        "def mmtokenizer(sentence):\n",
        "    return pds.tokenize(sentence, form=\"word\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gVZIJ3E7K6Zp"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[TRG_LANGUAGE] = mmtokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4dtrcSPK6Zp",
        "outputId": "f42b1d2a-812a-48fd-9ccd-3c8e3492c7e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
              " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS2R-zl1K6Zq",
        "outputId": "bea33de6-e396-4d7a-cb45-ef0714e4c95b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  \" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။\n",
            "Tokenization:  ['\"', 'ဒီ', 'ဟာ', 'သည်', 'အဲ့ဒီ', 'အချိန်', 'တုန်း', 'က', 'လက်ရာ', 'အမြောက်ဆုံး', 'ဖြစ်', 'တာ', 'ကြောင့်', 'တာ', 'ပို', 'ဆာရစ်မက်နဘုရား', 'ကျောင်း', 'ဖြစ်', 'လိမ့်', 'မယ်', 'လို့', '\"', 'သူ', 'မ', 'ခံစား', 'ရ', 'ပါ', 'သည်', '။']\n"
          ]
        }
      ],
      "source": [
        "#example of tokenization of the english part\n",
        "print(\"Sentence: \", sample[1])\n",
        "print(\"Tokenization: \", token_transform[TRG_LANGUAGE](sample[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JggUFfyTK6Zq"
      },
      "source": [
        "A function to tokenize our input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h1Vya8eMK6Zq"
      },
      "outputs": [],
      "source": [
        "# helper function to yield list of tokens\n",
        "# here data can be `train` or `val` or `test`\n",
        "def yield_tokens(data, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data:\n",
        "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpJ11fc-K6Zr"
      },
      "source": [
        "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6R_4LG3PK6Zr"
      },
      "outputs": [],
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "xTz4_WAIK6Zr"
      },
      "source": [
        "### Text to integers (Numericalization)\n",
        "\n",
        "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJj2GCBOK6Zr",
        "outputId": "65c2da26-9a7f-45c1-8b24-75e76af40f1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
              " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "next(iter(train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0ElfzNt3K6Zs"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln),\n",
        "                                                    min_freq=2,   #The minimum frequency needed to include a token in the vocabulary. if not, everything will be treated as UNK\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end\n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA8UmfooK6Zs",
        "outputId": "92c9d221-d890-4028-832e-1fda0c3b8c47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[795, 18, 12, 0, 12]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#see some example\n",
        "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EvEmNH1WK6Zs",
        "outputId": "2d7536c0-3299-459b-d719-8c42658c7cd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vessel'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "#we can reverse it....\n",
        "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
        "\n",
        "#print 1816, for example\n",
        "mapping[1891]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "brtYvmQaK6Zt",
        "outputId": "fa1cd6bc-11f9-40c6-de2e-25efb1b23ef6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#let's try unknown vocab\n",
        "mapping[0]\n",
        "#they will all map to <unk> which has 0 as integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIKll1sMK6Zt",
        "outputId": "62222977-80dd-456d-cd75-f818eb13f6e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<pad>', '<sos>', '<eos>')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#let's try special symbols\n",
        "mapping[1], mapping[2], mapping[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYGFCG1pK6Zu",
        "outputId": "1757400e-9688-4112-d993-96147eff170c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16009"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#check unique vocabularies\n",
        "len(mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "nZCV7YspK6aM"
      },
      "source": [
        "## 4. Preparing the dataloader\n",
        "\n",
        "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "qeuUdXFqK6aM"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and trg language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], # Tokenization\n",
        "                                               vocab_transform[ln], # Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_batch(batch):\n",
        "    src_batch, src_len_batch, trg_batch = [], [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(processed_text)\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "        src_len_batch.append(processed_text.size(0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
        "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHNPRWRK6aM"
      },
      "source": [
        "Create train, val, and test dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yn06bHqGK6aN"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(val,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
        "test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "sWnRSdosK6aN"
      },
      "outputs": [],
      "source": [
        "# for en, len, de in train_loader:\n",
        "#     break\n",
        "\n",
        "# print(en[1])\n",
        "# print(len[1])\n",
        "# print(de[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCBeuBS7K6aN"
      },
      "source": [
        "Let's test the train loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7xDizWnkK6aN"
      },
      "outputs": [],
      "source": [
        "for en, _, de in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV1ahfC_K6aO",
        "outputId": "ea395762-d346-4dbb-fb65-333a41918768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English shape:  torch.Size([64, 58])\n",
            "German shape:  torch.Size([64, 77])\n"
          ]
        }
      ],
      "source": [
        "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
        "print(\"German shape: \", de.shape)   # (batch_size, seq len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnthte7QK6aO"
      },
      "source": [
        "## 5. Design the model\n",
        "\n",
        "<img src=\"../figures/transformer-encoder.png\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy9ZYkFiK6aO"
      },
      "source": [
        "### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "QG4zK8MxK6aO"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        _src    = self.feedforward(src)\n",
        "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLUJO-L4K6aP"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Z7M1EEQBK6aP"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 500):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                           for _ in range(n_layers)])\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len    = src.shape[1]\n",
        "\n",
        "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, src_len]\n",
        "\n",
        "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        return src\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlGEudTGK6aP"
      },
      "source": [
        "### Mutli Head Attention Layer\n",
        "\n",
        "<img src = \"../figures/transformer-attention.png\" width=\"700\">\n",
        "\n",
        "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "d5hYl2o7K6aP"
      },
      "outputs": [],
      "source": [
        "# MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "# forward(src, src, src, src_mask)\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        assert hid_dim % n_heads == 0\n",
        "        self.hid_dim  = hid_dim\n",
        "        self.n_heads  = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "\n",
        "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        #Additional linear layer for additive attention mechanism\n",
        "        self.w1 = nn.Linear(self.head_dim, self.head_dim)\n",
        "        self.w2 = nn.Linear(self.head_dim, self.head_dim)\n",
        "        self.vt = nn.Linear(self.head_dim, 1)\n",
        "\n",
        "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.dropout  = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        #src, src, src, src_mask\n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        #Q=K=V: [batch_size, src len, hid_dim]\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        #Q = [batch_size, n heads, query len, head_dim]\n",
        "\n",
        "        # Additive Attention\n",
        "        q_len = query.shape[1]\n",
        "        qw1 = self.w1(Q).view(batch_size, self.n_heads, q_len, 1, self.head_dim)\n",
        "\n",
        "        k_len = key.shape[1]\n",
        "        kw2 = self.w2(K).view(batch_size, self.n_heads, 1, k_len, self.head_dim)\n",
        "\n",
        "        energy = torch.tanh(qw1 + kw2)\n",
        "        # energy = self.vt(energy).view(batch_size, self.n_heads, q_len, k_len @ self.n_heads, 1)\n",
        "        energy = self.vt(energy).squeeze(-1)\n",
        "\n",
        "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
        "        #energy = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        #for making attention to padding to 0\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "        #attention = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
        "        #x = [batch_size, n heads, query len, head dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
        "        #x = [batch_size, query len, n heads, head dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        return x, attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UomG5xQdK6aQ"
      },
      "source": [
        "### Position-wise Feedforward Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "htV0JYbTK6aQ"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = [batch size, src len, hid dim]\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "LykrEOEtK6aR"
      },
      "source": [
        "### Decoder Layer\n",
        "\n",
        "<img src = \"../figures/transformer-decoder.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Fuy7eJr2K6aR"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "        #attention = [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        _trg = self.feedforward(trg)\n",
        "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        return trg, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm5ukej_K6aR"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ahfHsJjXK6aR"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hid_dim, n_layers, n_heads,\n",
        "                 pf_dim, dropout, device,max_length = 500):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                            for _ in range(n_layers)])\n",
        "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len    = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, trg len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "        #attention: [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "        #output = [batch_size, trg len, output_dim]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oteod4JAK6aR"
      },
      "source": [
        "### Putting them together (become Seq2Seq!)\n",
        "\n",
        "Our `trg_sub_mask` will look something like this (for a target with 5 tokens):\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 1\\\\\n",
        "\\end{matrix}$$\n",
        "\n",
        "The \"subsequent\" mask is then logically anded with the padding mask, this combines the two masks ensuring both the subsequent tokens and the padding tokens cannot be attended to. For example if the last two tokens were `<pad>` tokens the mask would look like:\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "\\end{matrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ysOxmhXvK6aS"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "oZWTiCpzK6aS"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MtzV-1LGK6aT"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yqXLu1aGK6aT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411fe3b1-6c7b-4636-e97b-b710122dc928"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTransformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(16009, 256)\n",
              "    (pos_embedding): Embedding(500, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (w1): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (w2): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(12318, 256)\n",
              "    (pos_embedding): Embedding(500, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (w1): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (w2): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (w1): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (w2): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (vt): Linear(in_features=32, out_features=1, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=12318, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "hid_dim = 256\n",
        "enc_layers = 3\n",
        "dec_layers = 3\n",
        "enc_heads = 8\n",
        "dec_heads = 8\n",
        "enc_pf_dim = 512\n",
        "dec_pf_dim = 512\n",
        "enc_dropout = 0.1\n",
        "dec_dropout = 0.1\n",
        "\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "enc = Encoder(input_dim,\n",
        "              hid_dim,\n",
        "              enc_layers,\n",
        "              enc_heads,\n",
        "              enc_pf_dim,\n",
        "              enc_dropout,\n",
        "              device)\n",
        "\n",
        "dec = Decoder(output_dim,\n",
        "              hid_dim,\n",
        "              dec_layers,\n",
        "              dec_heads,\n",
        "              dec_pf_dim,\n",
        "              enc_dropout,\n",
        "              device)\n",
        "\n",
        "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4P78-BjeK6aU"
      },
      "outputs": [],
      "source": [
        "# input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "# output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "# hid_dim = 256\n",
        "# enc_layers = 3\n",
        "# dec_layers = 3\n",
        "# enc_heads = 8\n",
        "# dec_heads = 8\n",
        "# enc_pf_dim = 512\n",
        "# dec_pf_dim = 512\n",
        "# enc_dropout = 0.1\n",
        "# dec_dropout = 0.1\n",
        "\n",
        "# SRC_PAD_IDX = PAD_IDX\n",
        "# TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "# enc = Encoder(input_dim,\n",
        "#             hid_dim,\n",
        "#             enc_layers,\n",
        "#             enc_heads,\n",
        "#             enc_pf_dim,\n",
        "#             enc_dropout,\n",
        "#             device)\n",
        "\n",
        "# dec = Decoder(output_dim,\n",
        "#             hid_dim,\n",
        "#             dec_layers,\n",
        "#             dec_heads,\n",
        "#             dec_pf_dim,\n",
        "#             enc_dropout,\n",
        "#             device)\n",
        "\n",
        "# model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "# model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFzvKCwfK6aU",
        "outputId": "a10d850d-e5c7-4fe3-c707-04661fa128cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4098304\n",
            "128000\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "3153408\n",
            "128000\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            "  1024\n",
            "    32\n",
            "    32\n",
            "     1\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "3153408\n",
            " 12318\n",
            "______\n",
            "14646407\n"
          ]
        }
      ],
      "source": [
        "#we can print the complexity by the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "AxcjiUt-K6aV"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.0005\n",
        "\n",
        "#training hyperparameters\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agv6UxsnK6aV"
      },
      "source": [
        "Then, we'll define our training loop. This is the exact same as the one used in the previous tutorial.\n",
        "\n",
        "As we want our model to predict the `<eos>` token but not have it be an input into our model we simply slice the `<eos>` token off the end of the sequence. Thus:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\n",
        "\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\n",
        "\\end{align*}$$\n",
        "\n",
        "$x_i$ denotes actual target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the `<eos>` token:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{output} &= [y_1, y_2, y_3, eos]\n",
        "\\end{align*}$$\n",
        "\n",
        "$y_i$ denotes predicted target sequence element. We then calculate our loss using the original `trg` tensor with the `<sos>` token sliced off the front, leaving the `<eos>` token:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{output} &= [y_1, y_2, y_3, eos]\\\\\n",
        "\\text{trg[1:]} &= [x_1, x_2, x_3, eos]\n",
        "\\end{align*}$$\n",
        "\n",
        "We then calculate our losses and update our parameters as is standard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "stuN3JPOK6aV"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, src_len, trg in loader:\n",
        "\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg    = [batch size, trg len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.reshape(-1, output_dim)\n",
        "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
        "\n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg    = [batch size * trg len - 1]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRCysTsnK6aV"
      },
      "source": [
        "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "HYt_FQ73K6aV"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for src, src_len, trg in loader:\n",
        "\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCsQA3-fK6aW"
      },
      "source": [
        "### Putting everything together\n",
        "\n",
        "Finally, we train our actual model. This model is almost 3x faster than the convolutional sequence-to-sequence model and also achieves a lower validation perplexity!\n",
        "\n",
        "**Note: similar to CNN, this model always has a teacher forcing ratio of 1, i.e. it will always use the ground truth next token from the target sequence (this is simply because CNN do everything in parallel so we cannot have the next token). This means we cannot compare perplexity values against the previous models when they are using a teacher forcing ratio that is not 1. To understand this, try run previous tutorials with teaching forcing ratio of 1, you will get very low perplexity.  **   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "R7E7ePvNK6aW"
      },
      "outputs": [],
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "VXgvQIjwK6aW"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "jFibg1VgK6aX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708bffc3-48a3-4ce8-af25-70dccf60944f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 11s\n",
            "\tTrain Loss: 5.424 | Train PPL: 226.801\n",
            "\t Val. Loss: 4.481 |  Val. PPL:  88.327\n",
            "Epoch: 02 | Time: 1m 11s\n",
            "\tTrain Loss: 4.350 | Train PPL:  77.514\n",
            "\t Val. Loss: 4.140 |  Val. PPL:  62.809\n",
            "Epoch: 03 | Time: 1m 11s\n",
            "\tTrain Loss: 3.970 | Train PPL:  52.989\n",
            "\t Val. Loss: 3.993 |  Val. PPL:  54.196\n",
            "Epoch: 04 | Time: 1m 11s\n",
            "\tTrain Loss: 3.682 | Train PPL:  39.739\n",
            "\t Val. Loss: 3.914 |  Val. PPL:  50.090\n",
            "Epoch: 05 | Time: 1m 11s\n",
            "\tTrain Loss: 3.437 | Train PPL:  31.086\n",
            "\t Val. Loss: 3.883 |  Val. PPL:  48.589\n",
            "Epoch: 06 | Time: 1m 11s\n",
            "\tTrain Loss: 3.218 | Train PPL:  24.973\n",
            "\t Val. Loss: 3.866 |  Val. PPL:  47.733\n",
            "Epoch: 07 | Time: 1m 11s\n",
            "\tTrain Loss: 3.015 | Train PPL:  20.382\n",
            "\t Val. Loss: 3.910 |  Val. PPL:  49.885\n",
            "Epoch: 08 | Time: 1m 11s\n",
            "\tTrain Loss: 2.826 | Train PPL:  16.873\n",
            "\t Val. Loss: 3.951 |  Val. PPL:  51.962\n",
            "Epoch: 09 | Time: 1m 10s\n",
            "\tTrain Loss: 2.652 | Train PPL:  14.181\n",
            "\t Val. Loss: 3.998 |  Val. PPL:  54.501\n",
            "Epoch: 10 | Time: 1m 11s\n",
            "\tTrain Loss: 2.487 | Train PPL:  12.023\n",
            "\t Val. Loss: 4.079 |  Val. PPL:  59.071\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 10\n",
        "clip       = 1\n",
        "\n",
        "save_path = f'models/{model.__class__.__name__}-additive.pt'\n",
        "model_name = f'{model.__class__.__name__}-additive.pt'\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
        "\n",
        "    #for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "    #lower perplexity is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "tAnax8qCK6aX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "1a6045c3-98f8-4892-9776-9c41e8ea5862"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "DgkrM_dFK6aY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1335b50e-0601-4abf-c3da-5629ce704017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 3.842 | Test PPL:  46.629 |\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "meta = {\n",
        "    'token_transform': token_transform,\n",
        "    'vocab_transform': vocab_transform,\n",
        "}\n",
        "meta_name = 'meta-additive.pkl'\n",
        "pickle.dump(meta, open('models/meta-additive.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "bZ7IQJbShH0u"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNse8ZJQK6aY"
      },
      "source": [
        "## 7. Test on some random news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "lNFFuVu4K6aY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82ec3eec-736c-4c74-b007-6968c7ad1635"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "sample[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Cx3XVwfwK6aY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "410486f4-f64b-4343-e290-1d23f12ad754"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "sample[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "QajncYnQK6aZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dbfa869-7a4c-4355-c3e3-d8565af7be72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    2,   323,  7304,    13,    11,    32,    93,    29,     0,     0,\n",
              "          125,    32,    16,     4,   145, 11286,  2562,     7,    60,    64,\n",
              "            6,    11,     3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
        "src_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "5_d5lKk1K6aZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c3a5d3-ebe8-4a13-d78d-60ce51cce0f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,   34,   77,   93,    4, 1013,  123, 1454,   11, 2755,    0,   19,\n",
              "          84,   95,   84,  152,    0,  210,   19,   52,  212,   73,   34,   15,\n",
              "          26,  338,   30,   23,    4,    8,    3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
        "trg_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "bllrxtRIK6aZ"
      },
      "outputs": [],
      "source": [
        "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "pPzKCSOGK6aZ"
      },
      "outputs": [],
      "source": [
        "trg_text = trg_text.reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "0tVxozVpK6aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d56961-d06d-480e-c0d4-66a50d5dbfc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 23]), torch.Size([1, 31]))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "src_text.shape, trg_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "7o-U_lPLK6aa"
      },
      "outputs": [],
      "source": [
        "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "cKGWNz2OK6aa"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output, attentions = model(src_text, trg_text) #turn off teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "wbnmKWPSK6aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb344648-412b-4781-8158-5c62c565b215"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 31, 12318])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "output.shape #batch_size, trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOLbH_9HK6ab"
      },
      "source": [
        "Since batch size is 1, we just take off that dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "keItGqphK6ab"
      },
      "outputs": [],
      "source": [
        "output = output.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "-uR82XfkK6ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88cd539e-f5b7-43de-acad-d6da2895a700"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([31, 12318])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJqyK0P_K6ab"
      },
      "source": [
        "We shall remove the first token since it's zeroes anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "zLHcVfaCK6ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a042f38-838a-4ec3-b6f6-3771f1a35e31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 12318])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "output = output[1:]\n",
        "output.shape #trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKHG_7sMK6ac"
      },
      "source": [
        "Then we just take the top token with highest probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "A6UeZzwbK6ac"
      },
      "outputs": [],
      "source": [
        "output_max = output.argmax(1) #returns max indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "DHjJYn1UK6ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ea2e6a-287b-4af0-a5f4-4441e65f77dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([196, 123,  67,  67, 123,  31,  11,  67,   0,  19,   4,  95,  19,  95,\n",
              "         70,  19,  19,   4,  43,  73,  15,  15,  26,  11,  30,  23,   8,   8,\n",
              "          3,   4], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "output_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcQStPmbK6ac"
      },
      "source": [
        "Get the mapping of the target language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "9PTgwfQWK6ac"
      },
      "outputs": [],
      "source": [
        "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Dgj8YF2KK6ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af50a33-0e6f-4cf5-9ac2-d4869d70888d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ဒါ\n",
            "အချိန်\n",
            "၎င်း\n",
            "၎င်း\n",
            "အချိန်\n",
            "မှာ\n",
            "က\n",
            "၎င်း\n",
            "<unk>\n",
            "ဖြစ်\n",
            "သည်\n",
            "ကြောင့်\n",
            "ဖြစ်\n",
            "ကြောင့်\n",
            "၍\n",
            "ဖြစ်\n",
            "ဖြစ်\n",
            "သည်\n",
            "မည်\n",
            "လို့\n",
            "သူ\n",
            "သူ\n",
            "မ\n",
            "က\n",
            "ရ\n",
            "ပါ\n",
            "။\n",
            "။\n",
            "<eos>\n",
            "သည်\n"
          ]
        }
      ],
      "source": [
        "for token in output_max:\n",
        "    print(mapping[token.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAtej249K6ad"
      },
      "source": [
        "## 8. Attention\n",
        "\n",
        "Let's display the attentions to understand how the source text links with the generated text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "he4JNDc5K6ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf467ebb-05eb-44f3-ec9a-71f9545b4cd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 31, 23])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "attentions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fS6mDHcK6ad"
      },
      "source": [
        "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "oghBBae3K6ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54088545-5b91-4b2f-9021-7fad6e5ff86d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([31, 23])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "attention = attentions[0, 0, :, :]\n",
        "attention.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "dF-mBXSLK6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df74a879-8656-42cd-ffe1-76704a5c4207"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'She',\n",
              " 'feels',\n",
              " 'that',\n",
              " '\"',\n",
              " 'it',\n",
              " 'could',\n",
              " 'be',\n",
              " 'Taposiris',\n",
              " 'Magna',\n",
              " 'because',\n",
              " 'it',\n",
              " 'was',\n",
              " 'the',\n",
              " 'most',\n",
              " 'sacred',\n",
              " 'temple',\n",
              " 'of',\n",
              " 'its',\n",
              " 'time',\n",
              " '.',\n",
              " '\"',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
        "src_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "1sX1ZvjYK6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec6943f-356b-4707-9a6e-0579a44cf487"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'ဒါ',\n",
              " 'အချိန်',\n",
              " '၎င်း',\n",
              " '၎င်း',\n",
              " 'အချိန်',\n",
              " 'မှာ',\n",
              " 'က',\n",
              " '၎င်း',\n",
              " '<unk>',\n",
              " 'ဖြစ်',\n",
              " 'သည်',\n",
              " 'ကြောင့်',\n",
              " 'ဖြစ်',\n",
              " 'ကြောင့်',\n",
              " '၍',\n",
              " 'ဖြစ်',\n",
              " 'ဖြစ်',\n",
              " 'သည်',\n",
              " 'မည်',\n",
              " 'လို့',\n",
              " 'သူ',\n",
              " 'သူ',\n",
              " 'မ',\n",
              " 'က',\n",
              " 'ရ',\n",
              " 'ပါ',\n",
              " '။',\n",
              " '။',\n",
              " '<eos>',\n",
              " 'သည်']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
        "trg_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "FXKwnlj7K6ae"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "\n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "\n",
        "    ax.tick_params(labelsize=10)\n",
        "\n",
        "    y_ticks =  [''] + translation\n",
        "    x_ticks =  [''] + sentence\n",
        "\n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "HKyd-VmIK6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b7b1493-d6af-45ef-ddfb-b20cdae9bb04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-08ff35c238c4>:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels(x_ticks, rotation=45)\n",
            "<ipython-input-79-08ff35c238c4>:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels(y_ticks)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4114 (\\N{MYANMAR LETTER DA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4139 (\\N{MYANMAR VOWEL SIGN TALL AA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4129 (\\N{MYANMAR LETTER A}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4097 (\\N{MYANMAR LETTER KHA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4155 (\\N{MYANMAR CONSONANT SIGN MEDIAL YA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4141 (\\N{MYANMAR VOWEL SIGN I}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4116 (\\N{MYANMAR LETTER NA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4154 (\\N{MYANMAR SIGN ASAT}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4174 (\\N{MYANMAR SYMBOL AFOREMENTIONED}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4100 (\\N{MYANMAR LETTER NGA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4152 (\\N{MYANMAR SIGN VISARGA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4121 (\\N{MYANMAR LETTER MA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4158 (\\N{MYANMAR CONSONANT SIGN MEDIAL HA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4140 (\\N{MYANMAR VOWEL SIGN AA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4096 (\\N{MYANMAR LETTER KA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4118 (\\N{MYANMAR LETTER PHA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4156 (\\N{MYANMAR CONSONANT SIGN MEDIAL RA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4101 (\\N{MYANMAR LETTER CA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4126 (\\N{MYANMAR LETTER SA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4106 (\\N{MYANMAR LETTER NNYA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4145 (\\N{MYANMAR VOWEL SIGN E}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4151 (\\N{MYANMAR SIGN DOT BELOW}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4173 (\\N{MYANMAR SYMBOL COMPLETED}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4124 (\\N{MYANMAR LETTER LA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4143 (\\N{MYANMAR VOWEL SIGN U}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4144 (\\N{MYANMAR VOWEL SIGN UU}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4123 (\\N{MYANMAR LETTER RA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4117 (\\N{MYANMAR LETTER PA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4171 (\\N{MYANMAR SIGN SECTION}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display_attention(src_tokens, trg_tokens, attention)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dest = \"/content/drive/MyDrive/Colab_Notebooks/NLP/Assignment3/models\""
      ],
      "metadata": {
        "id": "hSJ6_k8MOVQe"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R models/$model_name $dest"
      ],
      "metadata": {
        "id": "UfXcghqyOYWH"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R models/$meta_name $dest"
      ],
      "metadata": {
        "id": "T9rERikgHlWU"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R models/$meta_name $dest"
      ],
      "metadata": {
        "id": "A0DBIHz1SSOD"
      },
      "execution_count": 84,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "714d3f4db9a58ba7d2f2a9a4fffe577af3df8551aebd380095064812e2e0a6a4"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}