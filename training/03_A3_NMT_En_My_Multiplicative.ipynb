{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW2Le2rdK6Zd"
      },
      "source": [
        "# Machine Translation + Transformer\n",
        "\n",
        "<img src = \"../figures/transformer1.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g05u7tTDOQxf",
        "outputId": "8c6248f1-37cd-40c7-e967-166264d6ccfb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f2B3PFbNNAd",
        "outputId": "215bd095-4bb6-4a69-fb9f-37c7300d039c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘models/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ8u6WwRK6Zh",
        "outputId": "913d91ab-2169-4014-f785-1196b9e9115f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyidaungsu in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyidaungsu) (1.23.5)\n",
            "Requirement already satisfied: python-crfsuite in /usr/local/lib/python3.10/dist-packages (from pyidaungsu) (0.9.10)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from pyidaungsu) (2.10.1)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from pyidaungsu) (2.11.1)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (from pyidaungsu) (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext->pyidaungsu) (67.7.2)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata) (1.3.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.23.5)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchtext) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.8.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyidaungsu\n",
        "!pip3 install torchdata\n",
        "!pip3 install torchtext\n",
        "!pip3 install portalocker\n",
        "!pip3 install datasets\n",
        "!pip3 install spacy\n",
        "!python3 -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW0fqtIgK6Zj",
        "outputId": "9bc79b87-a15a-46c9-cb5f-2a65ab340d02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch, torchdata, torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pyidaungsu as pds\n",
        "\n",
        "import random, math, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-u6vONbIK6Zj"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3o_5lt3dK6Zk",
        "outputId": "b474ac92-3021-468f-de0d-45844960fd65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dT2lraVxK6Zk",
        "outputId": "df17dc12-c51e-4181-dfcc-cff8fbef7bf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.16.0+cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "v_c3EBN7K6Zk"
      },
      "source": [
        "## 1. ETL: Loading the dataset\n",
        "\n",
        "**Note**: Here I chose to translate English to German, simply it is easier for myself, since I don't understand German so it is difficult for me to imagine a sentence during inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJYqEm7-K6Zl",
        "outputId": "0c7d0453-de4b-4ab6-d7b2-60805d377878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torchtext, datasets\n",
        "\n",
        "SRC_LANGUAGE = 'en'\n",
        "TRG_LANGUAGE = 'my'\n",
        "\n",
        "# train = Multi30k(split=('train'), language_pair=(SRC_LANGUAGE, TRG_LANGUAGE))\n",
        "dataset = datasets.load_dataset('myothiha/mm_eng_alt_corpus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlUB_lxuK6Zl",
        "outputId": "348aa31b-1bd6-4594-b40f-f9a831ec1761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "type(dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "75K3-3EdK6Zl"
      },
      "outputs": [],
      "source": [
        "train = [(row['en'], row['my']) for row in dataset['train']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU_Ouha8K6Zm",
        "outputId": "3acca99e-13c7-47e6-f62c-e52f88505e1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
              " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Z_dC0d7-K6Zm"
      },
      "source": [
        "## 2. EDA - simple investigation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUsY3lUnK6Zm",
        "outputId": "514ddd07-499c-482c-d13d-8e55e09a247f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
              " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#let's take a look at one example of train\n",
        "sample = train[0]\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnfX8Pj5K6Zn",
        "outputId": "384c0c44-b242-4967-94ca-088711b080ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16280"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_size = len(train)\n",
        "train_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlBPa57KK6Zn"
      },
      "source": [
        "Since 29001 is plenty,, we gonna call `random_split` to train, val and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mjZ9kynUK6Zn"
      },
      "outputs": [],
      "source": [
        "# train, val, test = train.random_split(total_length=train_size, weights = {\"train\": 0.7, \"val\": 0.2, \"test\": 0.1}, seed=999)\n",
        "val = [(row['en'], row['my']) for row in dataset['validation']]\n",
        "test = [(row['en'], row['my']) for row in dataset['test']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrwX_G-jK6Zn",
        "outputId": "deeff2c1-d433-4903-d1bb-23cadf184a6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16280"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_size = len(train)\n",
        "train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVsyuDedK6Zo",
        "outputId": "c6e975c7-b5f4-48c0-dc76-3703ddd2cf3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1809"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "val_size = len(val)\n",
        "val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv7qDMjpK6Zo",
        "outputId": "3f303314-4643-4d88-ba53-02315485d288"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2010"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "test_size = len(test)\n",
        "test_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "XOLSghmbK6Zo"
      },
      "source": [
        "## 3. Preprocessing\n",
        "\n",
        "### Tokenizing\n",
        "\n",
        "**Note**: the models must first be downloaded using the following on the command line:\n",
        "```\n",
        "python3 -m spacy download en_core_web_sm\n",
        "python3 -m spacy download de_core_news_sm\n",
        "```\n",
        "\n",
        "First, since we have two languages, let's create some constants to represent that.  Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dSzV7tBYK6Zp"
      },
      "outputs": [],
      "source": [
        "# !python3 -m spacy download en_core_web_sm\n",
        "# !python3 -m spacy download de_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "T2no_bINK6Zp"
      },
      "outputs": [],
      "source": [
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TNk_Io-HK6Zp"
      },
      "outputs": [],
      "source": [
        "# Myanmar word tokenizer.\n",
        "def mmtokenizer(sentence):\n",
        "    return pds.tokenize(sentence, form=\"word\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gVZIJ3E7K6Zp"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[TRG_LANGUAGE] = mmtokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4dtrcSPK6Zp",
        "outputId": "3f43d15c-d16f-4522-efbf-cc84722ab50b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
              " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS2R-zl1K6Zq",
        "outputId": "ef6d6bed-c947-481f-e947-1e0171e2f330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  \" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။\n",
            "Tokenization:  ['\"', 'ဒီ', 'ဟာ', 'သည်', 'အဲ့ဒီ', 'အချိန်', 'တုန်း', 'က', 'လက်ရာ', 'အမြောက်ဆုံး', 'ဖြစ်', 'တာ', 'ကြောင့်', 'တာ', 'ပို', 'ဆာရစ်မက်နဘုရား', 'ကျောင်း', 'ဖြစ်', 'လိမ့်', 'မယ်', 'လို့', '\"', 'သူ', 'မ', 'ခံစား', 'ရ', 'ပါ', 'သည်', '။']\n"
          ]
        }
      ],
      "source": [
        "#example of tokenization of the english part\n",
        "print(\"Sentence: \", sample[1])\n",
        "print(\"Tokenization: \", token_transform[TRG_LANGUAGE](sample[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JggUFfyTK6Zq"
      },
      "source": [
        "A function to tokenize our input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h1Vya8eMK6Zq"
      },
      "outputs": [],
      "source": [
        "# helper function to yield list of tokens\n",
        "# here data can be `train` or `val` or `test`\n",
        "def yield_tokens(data, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data:\n",
        "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpJ11fc-K6Zr"
      },
      "source": [
        "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6R_4LG3PK6Zr"
      },
      "outputs": [],
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "xTz4_WAIK6Zr"
      },
      "source": [
        "### Text to integers (Numericalization)\n",
        "\n",
        "Next we gonna create function (torchtext called vocabs) that turn these tokens into integers.  Here we use built in factory function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJj2GCBOK6Zr",
        "outputId": "a63a76d3-1835-46bf-81f0-8241ad28252f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"',\n",
              " '\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "next(iter(train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0ElfzNt3K6Zs"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln),\n",
        "                                                    min_freq=2,   #The minimum frequency needed to include a token in the vocabulary. if not, everything will be treated as UNK\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end\n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA8UmfooK6Zs",
        "outputId": "6808fea6-e8cc-4df4-f3d9-5898d7bb312e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[795, 18, 12, 0, 12]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#see some example\n",
        "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EvEmNH1WK6Zs",
        "outputId": "16c521f1-63c6-40ce-f80f-4a62fbf7203c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vessel'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "#we can reverse it....\n",
        "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
        "\n",
        "#print 1816, for example\n",
        "mapping[1891]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "brtYvmQaK6Zt",
        "outputId": "515a3cb0-000a-47d7-c4dc-f8a7aacc27e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#let's try unknown vocab\n",
        "mapping[0]\n",
        "#they will all map to <unk> which has 0 as integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIKll1sMK6Zt",
        "outputId": "e48391e5-201e-4241-9203-3977b9bb320b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<pad>', '<sos>', '<eos>')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#let's try special symbols\n",
        "mapping[1], mapping[2], mapping[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYGFCG1pK6Zu",
        "outputId": "53f7e874-e544-43ca-a808-5ccb9b102a5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16009"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#check unique vocabularies\n",
        "len(mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "nZCV7YspK6aM"
      },
      "source": [
        "## 4. Preparing the dataloader\n",
        "\n",
        "One thing we change here is the <code>collate_fn</code> which now also returns the length of sentence.  This is required for <code>packed_padded_sequence</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "qeuUdXFqK6aM"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and trg language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], # Tokenization\n",
        "                                               vocab_transform[ln], # Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_batch(batch):\n",
        "    src_batch, src_len_batch, trg_batch = [], [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(processed_text)\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "        src_len_batch.append(processed_text.size(0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
        "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHNPRWRK6aM"
      },
      "source": [
        "Create train, val, and test dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yn06bHqGK6aN"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(val,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
        "test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "sWnRSdosK6aN"
      },
      "outputs": [],
      "source": [
        "# for en, len, de in train_loader:\n",
        "#     break\n",
        "\n",
        "# print(en[1])\n",
        "# print(len[1])\n",
        "# print(de[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCBeuBS7K6aN"
      },
      "source": [
        "Let's test the train loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7xDizWnkK6aN"
      },
      "outputs": [],
      "source": [
        "for en, _, de in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV1ahfC_K6aO",
        "outputId": "0b70b99b-b24d-4db3-d3d5-a299eaa408e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English shape:  torch.Size([256, 67])\n",
            "German shape:  torch.Size([256, 104])\n"
          ]
        }
      ],
      "source": [
        "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
        "print(\"German shape: \", de.shape)   # (batch_size, seq len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnthte7QK6aO"
      },
      "source": [
        "## 5. Design the model\n",
        "\n",
        "<img src=\"../figures/transformer-encoder.png\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy9ZYkFiK6aO"
      },
      "source": [
        "### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "QG4zK8MxK6aO"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        _src    = self.feedforward(src)\n",
        "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLUJO-L4K6aP"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Z7M1EEQBK6aP"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 500):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                           for _ in range(n_layers)])\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len    = src.shape[1]\n",
        "\n",
        "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, src_len]\n",
        "\n",
        "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        return src\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlGEudTGK6aP"
      },
      "source": [
        "### Mutli Head Attention Layer\n",
        "\n",
        "<img src = \"../figures/transformer-attention.png\" width=\"700\">\n",
        "\n",
        "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}} \\big)V $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "d5hYl2o7K6aP"
      },
      "outputs": [],
      "source": [
        "# MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "# forward(src, src, src, src_mask)\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        assert hid_dim % n_heads == 0\n",
        "        self.hid_dim  = hid_dim\n",
        "        self.n_heads  = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "\n",
        "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.w = nn.Linear(self.head_dim, self.head_dim) # For Multiplicative attention layer.\n",
        "\n",
        "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.dropout  = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        #src, src, src, src_mask\n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        #Q=K=V: [batch_size, src len, hid_dim]\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        #Q = [batch_size, n heads, query len, head_dim]\n",
        "\n",
        "        # Scaled Multiplicative Attention\n",
        "        K_ = self.w(K)\n",
        "        # Q @ W @ KT (W is weight with d2 x d1 dimension [head_dim, head_dim])\n",
        "        energy = torch.matmul(Q, K_.transpose(-2, -1)) / self.scale\n",
        "\n",
        "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
        "        #energy = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        #for making attention to padding to 0\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "        #attention = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
        "        #x = [batch_size, n heads, query len, head dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
        "        #x = [batch_size, query len, n heads, head dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        return x, attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UomG5xQdK6aQ"
      },
      "source": [
        "### Position-wise Feedforward Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "htV0JYbTK6aQ"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = [batch size, src len, hid dim]\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "LykrEOEtK6aR"
      },
      "source": [
        "### Decoder Layer\n",
        "\n",
        "<img src = \"../figures/transformer-decoder.png\" >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Fuy7eJr2K6aR"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "        #attention = [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        _trg = self.feedforward(trg)\n",
        "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        return trg, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm5ukej_K6aR"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ahfHsJjXK6aR"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hid_dim, n_layers, n_heads,\n",
        "                 pf_dim, dropout, device,max_length = 500):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                            for _ in range(n_layers)])\n",
        "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len    = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, trg len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "        #attention: [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "        #output = [batch_size, trg len, output_dim]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oteod4JAK6aR"
      },
      "source": [
        "### Putting them together (become Seq2Seq!)\n",
        "\n",
        "Our `trg_sub_mask` will look something like this (for a target with 5 tokens):\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 0\\\\\n",
        "1 & 1 & 1 & 1 & 1\\\\\n",
        "\\end{matrix}$$\n",
        "\n",
        "The \"subsequent\" mask is then logically anded with the padding mask, this combines the two masks ensuring both the subsequent tokens and the padding tokens cannot be attended to. For example if the last two tokens were `<pad>` tokens the mask would look like:\n",
        "\n",
        "$$\\begin{matrix}\n",
        "1 & 0 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 0 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "1 & 1 & 1 & 0 & 0\\\\\n",
        "\\end{matrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ysOxmhXvK6aS"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "oZWTiCpzK6aS"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MtzV-1LGK6aT"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yqXLu1aGK6aT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4c4882-f0d6-4c7a-e01b-829cac865346"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTransformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(16009, 256)\n",
              "    (pos_embedding): Embedding(500, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (w): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(12318, 256)\n",
              "    (pos_embedding): Embedding(500, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (w): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (w): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=12318, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "hid_dim = 256\n",
        "enc_layers = 3\n",
        "dec_layers = 3\n",
        "enc_heads = 8\n",
        "dec_heads = 8\n",
        "enc_pf_dim = 512\n",
        "dec_pf_dim = 512\n",
        "enc_dropout = 0.1\n",
        "dec_dropout = 0.1\n",
        "\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "enc = Encoder(input_dim,\n",
        "              hid_dim,\n",
        "              enc_layers,\n",
        "              enc_heads,\n",
        "              enc_pf_dim,\n",
        "              enc_dropout,\n",
        "              device)\n",
        "\n",
        "dec = Decoder(output_dim,\n",
        "              hid_dim,\n",
        "              dec_layers,\n",
        "              dec_heads,\n",
        "              dec_pf_dim,\n",
        "              enc_dropout,\n",
        "              device)\n",
        "\n",
        "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4P78-BjeK6aU"
      },
      "outputs": [],
      "source": [
        "# input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "# output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "# hid_dim = 256\n",
        "# enc_layers = 3\n",
        "# dec_layers = 3\n",
        "# enc_heads = 8\n",
        "# dec_heads = 8\n",
        "# enc_pf_dim = 512\n",
        "# dec_pf_dim = 512\n",
        "# enc_dropout = 0.1\n",
        "# dec_dropout = 0.1\n",
        "\n",
        "# SRC_PAD_IDX = PAD_IDX\n",
        "# TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "# enc = Encoder(input_dim,\n",
        "#             hid_dim,\n",
        "#             enc_layers,\n",
        "#             enc_heads,\n",
        "#             enc_pf_dim,\n",
        "#             enc_dropout,\n",
        "#             device)\n",
        "\n",
        "# dec = Decoder(output_dim,\n",
        "#             hid_dim,\n",
        "#             dec_layers,\n",
        "#             dec_heads,\n",
        "#             dec_pf_dim,\n",
        "#             enc_dropout,\n",
        "#             device)\n",
        "\n",
        "# model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "# model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFzvKCwfK6aU",
        "outputId": "16d7218a-d909-4f2d-ec1e-e1e5abff6a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4098304\n",
            "128000\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "3153408\n",
            "128000\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "  1024\n",
            "    32\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "3153408\n",
            " 12318\n",
            "______\n",
            "14636606\n"
          ]
        }
      ],
      "source": [
        "#we can print the complexity by the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "AxcjiUt-K6aV"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.0005\n",
        "\n",
        "#training hyperparameters\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agv6UxsnK6aV"
      },
      "source": [
        "Then, we'll define our training loop. This is the exact same as the one used in the previous tutorial.\n",
        "\n",
        "As we want our model to predict the `<eos>` token but not have it be an input into our model we simply slice the `<eos>` token off the end of the sequence. Thus:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\n",
        "\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\n",
        "\\end{align*}$$\n",
        "\n",
        "$x_i$ denotes actual target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the `<eos>` token:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{output} &= [y_1, y_2, y_3, eos]\n",
        "\\end{align*}$$\n",
        "\n",
        "$y_i$ denotes predicted target sequence element. We then calculate our loss using the original `trg` tensor with the `<sos>` token sliced off the front, leaving the `<eos>` token:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\text{output} &= [y_1, y_2, y_3, eos]\\\\\n",
        "\\text{trg[1:]} &= [x_1, x_2, x_3, eos]\n",
        "\\end{align*}$$\n",
        "\n",
        "We then calculate our losses and update our parameters as is standard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "stuN3JPOK6aV"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, src_len, trg in loader:\n",
        "\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg    = [batch size, trg len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.reshape(-1, output_dim)\n",
        "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
        "\n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg    = [batch size * trg len - 1]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRCysTsnK6aV"
      },
      "source": [
        "Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "HYt_FQ73K6aV"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for src, src_len, trg in loader:\n",
        "\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCsQA3-fK6aW"
      },
      "source": [
        "### Putting everything together\n",
        "\n",
        "Finally, we train our actual model. This model is almost 3x faster than the convolutional sequence-to-sequence model and also achieves a lower validation perplexity!\n",
        "\n",
        "**Note: similar to CNN, this model always has a teacher forcing ratio of 1, i.e. it will always use the ground truth next token from the target sequence (this is simply because CNN do everything in parallel so we cannot have the next token). This means we cannot compare perplexity values against the previous models when they are using a teacher forcing ratio that is not 1. To understand this, try run previous tutorials with teaching forcing ratio of 1, you will get very low perplexity.  **   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "R7E7ePvNK6aW"
      },
      "outputs": [],
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "VXgvQIjwK6aW"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFibg1VgK6aX",
        "outputId": "d9b7d620-1eee-49e3-ab65-3418ec345257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 1s\n",
            "\tTrain Loss: 6.663 | Train PPL: 782.835\n",
            "\t Val. Loss: 5.307 |  Val. PPL: 201.708\n",
            "Epoch: 02 | Time: 1m 1s\n",
            "\tTrain Loss: 5.014 | Train PPL: 150.576\n",
            "\t Val. Loss: 4.601 |  Val. PPL:  99.588\n",
            "Epoch: 03 | Time: 1m 1s\n",
            "\tTrain Loss: 4.504 | Train PPL:  90.378\n",
            "\t Val. Loss: 4.345 |  Val. PPL:  77.061\n",
            "Epoch: 04 | Time: 1m 1s\n",
            "\tTrain Loss: 4.195 | Train PPL:  66.329\n",
            "\t Val. Loss: 4.190 |  Val. PPL:  66.039\n",
            "Epoch: 05 | Time: 1m 1s\n",
            "\tTrain Loss: 3.950 | Train PPL:  51.930\n",
            "\t Val. Loss: 4.113 |  Val. PPL:  61.117\n",
            "Epoch: 06 | Time: 1m 1s\n",
            "\tTrain Loss: 3.735 | Train PPL:  41.873\n",
            "\t Val. Loss: 4.044 |  Val. PPL:  57.070\n",
            "Epoch: 07 | Time: 1m 1s\n",
            "\tTrain Loss: 3.538 | Train PPL:  34.381\n",
            "\t Val. Loss: 4.013 |  Val. PPL:  55.296\n",
            "Epoch: 08 | Time: 1m 1s\n",
            "\tTrain Loss: 3.357 | Train PPL:  28.700\n",
            "\t Val. Loss: 3.991 |  Val. PPL:  54.124\n",
            "Epoch: 09 | Time: 1m 1s\n",
            "\tTrain Loss: 3.182 | Train PPL:  24.086\n",
            "\t Val. Loss: 3.994 |  Val. PPL:  54.298\n",
            "Epoch: 10 | Time: 1m 1s\n",
            "\tTrain Loss: 3.019 | Train PPL:  20.475\n",
            "\t Val. Loss: 4.011 |  Val. PPL:  55.186\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 10\n",
        "clip       = 1\n",
        "\n",
        "save_path = f'models/{model.__class__.__name__}-multiplicative.pt'\n",
        "model_name = f'{model.__class__.__name__}-multiplicative.pt'\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
        "\n",
        "    #for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "    #lower perplexity is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "tAnax8qCK6aX",
        "outputId": "aa69f592-0e5d-46ea-8964-5d15d94bf581"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgkrM_dFK6aY",
        "outputId": "31418c96-4a6c-4aab-e33d-d15b01ac2cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 3.966 | Test PPL:  52.748 |\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "meta = {\n",
        "    'token_transform': token_transform,\n",
        "    'vocab_transform': vocab_transform,\n",
        "}\n",
        "meta_name = 'meta-multiplicative.pkl'\n",
        "pickle.dump(meta, open('models/meta-multiplicative.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "Z5pNBMHSe5Bo"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNse8ZJQK6aY"
      },
      "source": [
        "## 7. Test on some random news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lNFFuVu4K6aY",
        "outputId": "fb2f9678-55a7-4b81-ac94-2c8bf31668be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'She feels that \"it could be Taposiris Magna because it was the most sacred temple of its time.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "sample[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Cx3XVwfwK6aY",
        "outputId": "791f6fb3-1255-4a01-83f7-5c48015827b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" ဒီဟာ သည် အဲ့ဒီ အချိန်တုန်း က လက်ရာအမြောက်ဆုံး ဖြစ်တာ ကြောင့် တာပိုဆာရစ် မက်န ဘုရားကျောင်း ဖြစ်လိမ့်မယ် လို့ \" သူမ ခံစားရပါသည် ။'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "sample[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QajncYnQK6aZ",
        "outputId": "a6d9e5a8-6dd4-45b0-9d0b-493a4b0ed486"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    2,   323,  7304,    13,    11,    32,    93,    29,     0,     0,\n",
              "          125,    32,    16,     4,   145, 11286,  2562,     7,    60,    64,\n",
              "            6,    11,     3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
        "src_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_d5lKk1K6aZ",
        "outputId": "d5a969a5-2fe0-49b7-efbd-ebbacbc4669e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,   34,   77,   93,    4, 1013,  123, 1454,   11, 2755,    0,   19,\n",
              "          84,   95,   84,  152,    0,  210,   19,   52,  212,   73,   34,   15,\n",
              "          26,  338,   30,   23,    4,    8,    3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
        "trg_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "bllrxtRIK6aZ"
      },
      "outputs": [],
      "source": [
        "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "pPzKCSOGK6aZ"
      },
      "outputs": [],
      "source": [
        "trg_text = trg_text.reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tVxozVpK6aa",
        "outputId": "9ee8fcf7-1a46-46c0-86fe-9eb8d21d2d18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 23]), torch.Size([1, 31]))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "src_text.shape, trg_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "7o-U_lPLK6aa"
      },
      "outputs": [],
      "source": [
        "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "cKGWNz2OK6aa"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output, attentions = model(src_text, trg_text) #turn off teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbnmKWPSK6aa",
        "outputId": "c4f5ff98-4b95-4a7c-fcc1-2afe2a290788"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 31, 12318])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "output.shape #batch_size, trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOLbH_9HK6ab"
      },
      "source": [
        "Since batch size is 1, we just take off that dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "keItGqphK6ab"
      },
      "outputs": [],
      "source": [
        "output = output.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uR82XfkK6ab",
        "outputId": "3159c41c-4566-4291-af56-915d93478bbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([31, 12318])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJqyK0P_K6ab"
      },
      "source": [
        "We shall remove the first token since it's zeroes anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLHcVfaCK6ab",
        "outputId": "5057ca5a-c54f-4185-fdca-b47d4b1f8ad7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 12318])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "output = output[1:]\n",
        "output.shape #trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKHG_7sMK6ac"
      },
      "source": [
        "Then we just take the top token with highest probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "A6UeZzwbK6ac"
      },
      "outputs": [],
      "source": [
        "output_max = output.argmax(1) #returns max indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHjJYn1UK6ac",
        "outputId": "999956f6-4af4-4f5a-dd80-a379d4e3eea1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([135, 123,   0,   0, 123,  31,  23,   0,   0,  23,  23,  19,  19,  23,\n",
              "         22,  23,  23,  23, 212,  34,  15,   0,  26,  23,  30,  23,  39,   8,\n",
              "          3,  23], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "output_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcQStPmbK6ac"
      },
      "source": [
        "Get the mapping of the target language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "9PTgwfQWK6ac"
      },
      "outputs": [],
      "source": [
        "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgj8YF2KK6ad",
        "outputId": "fbadae60-3687-4367-b64a-3755a052a68c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "သူမ\n",
            "အချိန်\n",
            "<unk>\n",
            "<unk>\n",
            "အချိန်\n",
            "မှာ\n",
            "ပါ\n",
            "<unk>\n",
            "<unk>\n",
            "ပါ\n",
            "ပါ\n",
            "ဖြစ်\n",
            "ဖြစ်\n",
            "ပါ\n",
            "ပြီး\n",
            "ပါ\n",
            "ပါ\n",
            "ပါ\n",
            "မယ်\n",
            "\"\n",
            "သူ\n",
            "<unk>\n",
            "မ\n",
            "ပါ\n",
            "ရ\n",
            "ပါ\n",
            "တယ်\n",
            "။\n",
            "<eos>\n",
            "ပါ\n"
          ]
        }
      ],
      "source": [
        "for token in output_max:\n",
        "    print(mapping[token.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAtej249K6ad"
      },
      "source": [
        "## 8. Attention\n",
        "\n",
        "Let's display the attentions to understand how the source text links with the generated text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he4JNDc5K6ad",
        "outputId": "af8f4467-11ad-4e80-ea0d-6463b445c575"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 31, 23])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "attentions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fS6mDHcK6ad"
      },
      "source": [
        "Since there are 8 heads, we can look at just 1 head for sake of simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oghBBae3K6ad",
        "outputId": "d00e8485-e25a-42df-faaa-6571917aaa3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([31, 23])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "attention = attentions[0, 0, :, :]\n",
        "attention.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF-mBXSLK6ae",
        "outputId": "8ab513c8-e2a4-48f0-a058-9ec2d74db893"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'She',\n",
              " 'feels',\n",
              " 'that',\n",
              " '\"',\n",
              " 'it',\n",
              " 'could',\n",
              " 'be',\n",
              " 'Taposiris',\n",
              " 'Magna',\n",
              " 'because',\n",
              " 'it',\n",
              " 'was',\n",
              " 'the',\n",
              " 'most',\n",
              " 'sacred',\n",
              " 'temple',\n",
              " 'of',\n",
              " 'its',\n",
              " 'time',\n",
              " '.',\n",
              " '\"',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
        "src_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sX1ZvjYK6ae",
        "outputId": "3a438e85-2455-4bd2-82d7-6178758876c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'သူမ',\n",
              " 'အချိန်',\n",
              " '<unk>',\n",
              " '<unk>',\n",
              " 'အချိန်',\n",
              " 'မှာ',\n",
              " 'ပါ',\n",
              " '<unk>',\n",
              " '<unk>',\n",
              " 'ပါ',\n",
              " 'ပါ',\n",
              " 'ဖြစ်',\n",
              " 'ဖြစ်',\n",
              " 'ပါ',\n",
              " 'ပြီး',\n",
              " 'ပါ',\n",
              " 'ပါ',\n",
              " 'ပါ',\n",
              " 'မယ်',\n",
              " '\"',\n",
              " 'သူ',\n",
              " '<unk>',\n",
              " 'မ',\n",
              " 'ပါ',\n",
              " 'ရ',\n",
              " 'ပါ',\n",
              " 'တယ်',\n",
              " '။',\n",
              " '<eos>',\n",
              " 'ပါ']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
        "trg_tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWe-x9ELuzmr",
        "outputId": "fd75eb25-e6e3-4be3-8ba4-67710eb11453"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2,   323,  7304,    13,    11,    32,    93,    29,     0,     0,\n",
              "           125,    32,    16,     4,   145, 11286,  2562,     7,    60,    64,\n",
              "             6,    11,     3]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "# src_mask = model.make_src_mask(src_text)\n",
        "# enc_src = model.encoder(src_text, src_mask)\n",
        "\n",
        "# trg_indexes = [SOS_IDX]\n",
        "\n",
        "# max_len = 50\n",
        "# outputs = []\n",
        "# for i in range(max_len):\n",
        "#     trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "#     trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "#     pred_token = output.argmax(2)[:, -1].item()\n",
        "#     trg_indexes.append(pred_token)\n",
        "\n",
        "#     if pred_token == EOS_IDX:\n",
        "#         break\n",
        "\n",
        "# trg_tokens = [vocab_transform[TRG_LANGUAGE].get_itos()[i] for i in trg_indexes]\n",
        "\n",
        "# \" \".join(trg_tokens[1:-1])"
      ],
      "metadata": {
        "id": "vZAC0vAMsgGL"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "FXKwnlj7K6ae"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "\n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "\n",
        "    ax.tick_params(labelsize=10)\n",
        "\n",
        "    y_ticks =  [''] + translation\n",
        "    x_ticks =  [''] + sentence\n",
        "\n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HKyd-VmIK6ae",
        "outputId": "3f211723-7b2e-4066-b033-0c739d4096b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-08ff35c238c4>:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels(x_ticks, rotation=45)\n",
            "<ipython-input-81-08ff35c238c4>:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels(y_ticks)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4126 (\\N{MYANMAR LETTER SA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4144 (\\N{MYANMAR VOWEL SIGN UU}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4121 (\\N{MYANMAR LETTER MA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4129 (\\N{MYANMAR LETTER A}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4097 (\\N{MYANMAR LETTER KHA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4155 (\\N{MYANMAR CONSONANT SIGN MEDIAL YA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4141 (\\N{MYANMAR VOWEL SIGN I}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4116 (\\N{MYANMAR LETTER NA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4154 (\\N{MYANMAR SIGN ASAT}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4158 (\\N{MYANMAR CONSONANT SIGN MEDIAL HA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4140 (\\N{MYANMAR VOWEL SIGN AA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4117 (\\N{MYANMAR LETTER PA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4139 (\\N{MYANMAR VOWEL SIGN TALL AA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4118 (\\N{MYANMAR LETTER PHA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4156 (\\N{MYANMAR CONSONANT SIGN MEDIAL RA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4101 (\\N{MYANMAR LETTER CA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4142 (\\N{MYANMAR VOWEL SIGN II}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4152 (\\N{MYANMAR SIGN VISARGA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4122 (\\N{MYANMAR LETTER YA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4123 (\\N{MYANMAR LETTER RA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4112 (\\N{MYANMAR LETTER TA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 4171 (\\N{MYANMAR SIGN SECTION}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display_attention(src_tokens, trg_tokens, attention)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dest = \"/content/drive/MyDrive/Colab_Notebooks/NLP/Assignment3/models\""
      ],
      "metadata": {
        "id": "hSJ6_k8MOVQe"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R models/$model_name $dest"
      ],
      "metadata": {
        "id": "UfXcghqyOYWH"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R models/$meta_name $dest"
      ],
      "metadata": {
        "id": "ftps16GeSUeQ"
      },
      "execution_count": 85,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "714d3f4db9a58ba7d2f2a9a4fffe577af3df8551aebd380095064812e2e0a6a4"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}